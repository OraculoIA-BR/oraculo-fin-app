module.exports = {

"[project]/node_modules/@genkit-ai/googleai/lib/common.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toESM = (mod, isNodeMode, target)=>(target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(// If the importer is in node compatibility mode or this is not an ESM
    // file that has been converted to a CommonJS file using a Babel-
    // compatible transform (i.e. "__esModule" has not been set), then set
    // "default" to the CommonJS "module.exports" for node compatibility.
    isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", {
        value: mod,
        enumerable: true
    }) : target, mod));
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var common_exports = {};
__export(common_exports, {
    getApiKeyFromEnvVar: ()=>getApiKeyFromEnvVar
});
module.exports = __toCommonJS(common_exports);
var import_process = __toESM(__turbopack_context__.r("[externals]/process [external] (process, cjs)"));
function getApiKeyFromEnvVar() {
    return import_process.default.env.GEMINI_API_KEY || import_process.default.env.GOOGLE_API_KEY || import_process.default.env.GOOGLE_GENAI_API_KEY;
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    getApiKeyFromEnvVar
}); //# sourceMappingURL=common.js.map
}}),
"[project]/node_modules/@genkit-ai/googleai/lib/embedder.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var embedder_exports = {};
__export(embedder_exports, {
    GeminiEmbeddingConfigSchema: ()=>GeminiEmbeddingConfigSchema,
    SUPPORTED_MODELS: ()=>SUPPORTED_MODELS,
    TaskTypeSchema: ()=>TaskTypeSchema,
    defineGoogleAIEmbedder: ()=>defineGoogleAIEmbedder,
    textEmbedding004: ()=>textEmbedding004,
    textEmbeddingGecko001: ()=>textEmbeddingGecko001
});
module.exports = __toCommonJS(embedder_exports);
var import_generative_ai = __turbopack_context__.r("[project]/node_modules/@google/generative-ai/dist/index.js [app-rsc] (ecmascript)");
var import_genkit = __turbopack_context__.r("[project]/node_modules/genkit/lib/index.js [app-rsc] (ecmascript)");
var import_embedder = __turbopack_context__.r("[project]/node_modules/genkit/lib/embedder.js [app-rsc] (ecmascript)");
var import_common = __turbopack_context__.r("[project]/node_modules/@genkit-ai/googleai/lib/common.js [app-rsc] (ecmascript)");
const TaskTypeSchema = import_genkit.z.enum([
    "RETRIEVAL_DOCUMENT",
    "RETRIEVAL_QUERY",
    "SEMANTIC_SIMILARITY",
    "CLASSIFICATION",
    "CLUSTERING"
]);
const GeminiEmbeddingConfigSchema = import_genkit.z.object({
    /** Override the API key provided at plugin initialization. */ apiKey: import_genkit.z.string().optional(),
    /**
   * The `task_type` parameter is defined as the intended downstream application to help the model
   * produce better quality embeddings.
   **/ taskType: TaskTypeSchema.optional(),
    title: import_genkit.z.string().optional(),
    version: import_genkit.z.string().optional(),
    /**
   * The `outputDimensionality` parameter allows you to specify the dimensionality of the embedding output.
   * By default, the model generates embeddings with 768 dimensions. Models such as
   * `text-embedding-004`, `text-embedding-005`, and `text-multilingual-embedding-002`
   * allow the output dimensionality to be adjusted between 1 and 768.
   * By selecting a smaller output dimensionality, users can save memory and storage space, leading to more efficient computations.
   **/ outputDimensionality: import_genkit.z.number().min(1).max(768).optional()
});
const textEmbeddingGecko001 = (0, import_embedder.embedderRef)({
    name: "googleai/embedding-001",
    configSchema: GeminiEmbeddingConfigSchema,
    info: {
        dimensions: 768,
        label: "Google Gen AI - Text Embedding Gecko (Legacy)",
        supports: {
            input: [
                "text"
            ]
        }
    }
});
const textEmbedding004 = (0, import_embedder.embedderRef)({
    name: "googleai/text-embedding-004",
    configSchema: GeminiEmbeddingConfigSchema,
    info: {
        dimensions: 768,
        label: "Google Gen AI - Text Embedding 001",
        supports: {
            input: [
                "text"
            ]
        }
    }
});
const SUPPORTED_MODELS = {
    "embedding-001": textEmbeddingGecko001,
    "text-embedding-004": textEmbedding004
};
function defineGoogleAIEmbedder(ai, name, pluginOptions) {
    let apiKey;
    if (pluginOptions.apiKey !== false) {
        apiKey = pluginOptions?.apiKey || (0, import_common.getApiKeyFromEnvVar)();
        if (!apiKey) throw new Error("Please pass in the API key or set either GEMINI_API_KEY or GOOGLE_API_KEY environment variable.\nFor more details see https://genkit.dev/docs/plugins/google-genai");
    }
    const embedder = SUPPORTED_MODELS[name] ?? (0, import_embedder.embedderRef)({
        name,
        configSchema: GeminiEmbeddingConfigSchema,
        info: {
            dimensions: 768,
            label: `Google AI - ${name}`,
            supports: {
                input: [
                    "text",
                    "image",
                    "video"
                ]
            }
        }
    });
    const apiModelName = embedder.name.startsWith("googleai/") ? embedder.name.substring("googleai/".length) : embedder.name;
    return ai.defineEmbedder({
        name: embedder.name,
        configSchema: GeminiEmbeddingConfigSchema,
        info: embedder.info
    }, async (input, options)=>{
        if (pluginOptions.apiKey === false && !options?.apiKey) {
            throw new import_genkit.GenkitError({
                status: "INVALID_ARGUMENT",
                message: "GoogleAI plugin was initialized with {apiKey: false} but no apiKey configuration was passed at call time."
            });
        }
        const client = new import_generative_ai.GoogleGenerativeAI(options?.apiKey || apiKey).getGenerativeModel({
            model: options?.version || embedder.config?.version || embedder.version || apiModelName
        });
        const embeddings = await Promise.all(input.map(async (doc)=>{
            const response = await client.embedContent({
                taskType: options?.taskType,
                title: options?.title,
                content: {
                    role: "",
                    parts: [
                        {
                            text: doc.text
                        }
                    ]
                },
                outputDimensionality: options?.outputDimensionality
            });
            const values = response.embedding.values;
            return {
                embedding: values
            };
        }));
        return {
            embeddings
        };
    });
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    GeminiEmbeddingConfigSchema,
    SUPPORTED_MODELS,
    TaskTypeSchema,
    defineGoogleAIEmbedder,
    textEmbedding004,
    textEmbeddingGecko001
}); //# sourceMappingURL=embedder.js.map
}}),
"[project]/node_modules/@genkit-ai/googleai/lib/context-caching/constants.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var constants_exports = {};
__export(constants_exports, {
    CONTEXT_CACHE_SUPPORTED_MODELS: ()=>CONTEXT_CACHE_SUPPORTED_MODELS,
    DEFAULT_TTL: ()=>DEFAULT_TTL,
    INVALID_ARGUMENT_MESSAGES: ()=>INVALID_ARGUMENT_MESSAGES
});
module.exports = __toCommonJS(constants_exports);
const CONTEXT_CACHE_SUPPORTED_MODELS = [
    "gemini-1.5-flash-001",
    "gemini-1.5-pro-001"
];
const INVALID_ARGUMENT_MESSAGES = {
    modelVersion: `Model version is required for context caching, supported only in ${CONTEXT_CACHE_SUPPORTED_MODELS.join(",")} models.`,
    tools: "Context caching cannot be used simultaneously with tools.",
    codeExecution: "Context caching cannot be used simultaneously with code execution."
};
const DEFAULT_TTL = 300;
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    CONTEXT_CACHE_SUPPORTED_MODELS,
    DEFAULT_TTL,
    INVALID_ARGUMENT_MESSAGES
}); //# sourceMappingURL=constants.js.map
}}),
"[project]/node_modules/@genkit-ai/googleai/lib/context-caching/types.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var types_exports = {};
__export(types_exports, {
    cacheConfigDetailsSchema: ()=>cacheConfigDetailsSchema,
    cacheConfigSchema: ()=>cacheConfigSchema
});
module.exports = __toCommonJS(types_exports);
var import_genkit = __turbopack_context__.r("[project]/node_modules/genkit/lib/index.js [app-rsc] (ecmascript)");
const cacheConfigSchema = import_genkit.z.union([
    import_genkit.z.boolean(),
    import_genkit.z.object({
        ttlSeconds: import_genkit.z.number().optional()
    }).passthrough()
]);
const cacheConfigDetailsSchema = import_genkit.z.object({
    cacheConfig: cacheConfigSchema,
    endOfCachedContents: import_genkit.z.number()
});
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    cacheConfigDetailsSchema,
    cacheConfigSchema
}); //# sourceMappingURL=types.js.map
}}),
"[project]/node_modules/@genkit-ai/googleai/lib/context-caching/utils.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toESM = (mod, isNodeMode, target)=>(target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(// If the importer is in node compatibility mode or this is not an ESM
    // file that has been converted to a CommonJS file using a Babel-
    // compatible transform (i.e. "__esModule" has not been set), then set
    // "default" to the CommonJS "module.exports" for node compatibility.
    isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", {
        value: mod,
        enumerable: true
    }) : target, mod));
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var utils_exports = {};
__export(utils_exports, {
    calculateTTL: ()=>calculateTTL,
    extractCacheConfig: ()=>extractCacheConfig,
    findLastIndex: ()=>findLastIndex,
    generateCacheKey: ()=>generateCacheKey,
    getContentForCache: ()=>getContentForCache,
    lookupContextCache: ()=>lookupContextCache,
    validateContextCacheRequest: ()=>validateContextCacheRequest
});
module.exports = __toCommonJS(utils_exports);
var import_crypto = __toESM(__turbopack_context__.r("[externals]/crypto [external] (crypto, cjs)"));
var import_genkit = __turbopack_context__.r("[project]/node_modules/genkit/lib/index.js [app-rsc] (ecmascript)");
var import_constants = __turbopack_context__.r("[project]/node_modules/@genkit-ai/googleai/lib/context-caching/constants.js [app-rsc] (ecmascript)");
var import_types = __turbopack_context__.r("[project]/node_modules/@genkit-ai/googleai/lib/context-caching/types.js [app-rsc] (ecmascript)");
function generateCacheKey(request) {
    return import_crypto.default.createHash("sha256").update(JSON.stringify(request)).digest("hex");
}
function getContentForCache(request, chatRequest, modelVersion, cacheConfigDetails) {
    if (!modelVersion) {
        throw new Error("No model version provided for context caching");
    }
    if (!chatRequest.history?.length) {
        throw new Error("No history provided for context caching");
    }
    validateHistoryLength(request, chatRequest);
    const { endOfCachedContents, cacheConfig } = cacheConfigDetails;
    const cachedContent = {
        model: modelVersion,
        contents: chatRequest.history.slice(0, endOfCachedContents + 1)
    };
    chatRequest.history = chatRequest.history.slice(endOfCachedContents + 1);
    return {
        cachedContent,
        chatRequest,
        cacheConfig
    };
}
function validateHistoryLength(request, chatRequest) {
    if (chatRequest.history?.length !== request.messages.length - 1) {
        throw new import_genkit.GenkitError({
            status: "INTERNAL",
            message: "Genkit request history and Gemini chat request history length do not match"
        });
    }
}
async function lookupContextCache(cacheManager, cacheKey, maxPages = 100, pageSize = 100) {
    let currentPage = 0;
    let pageToken;
    try {
        while(currentPage < maxPages){
            const { cachedContents, nextPageToken } = await cacheManager.list({
                pageSize,
                pageToken
            });
            const found = cachedContents?.find((content)=>content.displayName === cacheKey);
            if (found) return found;
            if (!nextPageToken) break;
            pageToken = nextPageToken;
            currentPage++;
        }
    } catch (error) {
        const message = error instanceof Error ? error.message : "Unknown Network Error";
        throw new import_genkit.GenkitError({
            status: "INTERNAL",
            message: `Error looking up context cache: ${message}`
        });
    }
    return null;
}
const extractCacheConfig = (request)=>{
    const endOfCachedContents = findLastIndex(request.messages, (message)=>!!message.metadata?.cache);
    return endOfCachedContents === -1 ? null : {
        endOfCachedContents,
        cacheConfig: import_types.cacheConfigSchema.parse(request.messages[endOfCachedContents].metadata?.cache)
    };
};
function validateContextCacheRequest(request, modelVersion) {
    if (!modelVersion || !import_constants.CONTEXT_CACHE_SUPPORTED_MODELS.includes(modelVersion)) {
        throw new import_genkit.GenkitError({
            status: "INVALID_ARGUMENT",
            message: import_constants.INVALID_ARGUMENT_MESSAGES.modelVersion
        });
    }
    if (request.tools?.length) throw new import_genkit.GenkitError({
        status: "INVALID_ARGUMENT",
        message: import_constants.INVALID_ARGUMENT_MESSAGES.tools
    });
    if (request.config?.codeExecution) throw new import_genkit.GenkitError({
        status: "INVALID_ARGUMENT",
        message: import_constants.INVALID_ARGUMENT_MESSAGES.codeExecution
    });
    return true;
}
function findLastIndex(array, callback) {
    for(let i = array.length - 1; i >= 0; i--){
        if (callback(array[i], i, array)) return i;
    }
    return -1;
}
function calculateTTL(cacheConfig) {
    if (cacheConfig.cacheConfig === true) {
        return import_constants.DEFAULT_TTL;
    }
    if (cacheConfig.cacheConfig === false) {
        return 0;
    }
    return cacheConfig.cacheConfig.ttlSeconds || import_constants.DEFAULT_TTL;
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    calculateTTL,
    extractCacheConfig,
    findLastIndex,
    generateCacheKey,
    getContentForCache,
    lookupContextCache,
    validateContextCacheRequest
}); //# sourceMappingURL=utils.js.map
}}),
"[project]/node_modules/@genkit-ai/googleai/lib/context-caching/index.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var context_caching_exports = {};
__export(context_caching_exports, {
    handleCacheIfNeeded: ()=>handleCacheIfNeeded,
    handleContextCache: ()=>handleContextCache
});
module.exports = __toCommonJS(context_caching_exports);
var import_server = __turbopack_context__.r("[project]/node_modules/@google/generative-ai/dist/server/index.js [app-rsc] (ecmascript)");
var import_genkit = __turbopack_context__.r("[project]/node_modules/genkit/lib/index.js [app-rsc] (ecmascript)");
var import_logging = __turbopack_context__.r("[project]/node_modules/genkit/lib/logging.js [app-rsc] (ecmascript)");
var import_utils = __turbopack_context__.r("[project]/node_modules/@genkit-ai/googleai/lib/context-caching/utils.js [app-rsc] (ecmascript)");
async function handleContextCache(apiKey, request, chatRequest, modelVersion, cacheConfigDetails) {
    const cacheManager = new import_server.GoogleAICacheManager(apiKey);
    const { cachedContent, chatRequest: newChatRequest } = (0, import_utils.getContentForCache)(request, chatRequest, modelVersion, cacheConfigDetails);
    cachedContent.model = modelVersion;
    const cacheKey = (0, import_utils.generateCacheKey)(cachedContent);
    cachedContent.displayName = cacheKey;
    let cache = await (0, import_utils.lookupContextCache)(cacheManager, cacheKey);
    import_logging.logger.debug(`Cache hit: ${cache ? "true" : "false"}`);
    if (!cache) {
        try {
            import_logging.logger.debug("No cache found, creating one.");
            const createParams = {
                ...cachedContent,
                ttlSeconds: (0, import_utils.calculateTTL)(cacheConfigDetails)
            };
            cache = await cacheManager.create(createParams);
            import_logging.logger.debug(`Created new cache entry with key: ${cacheKey}`);
        } catch (cacheError) {
            import_logging.logger.error(`Failed to create cache with key ${cacheKey}: ${cacheError}`);
            throw new import_genkit.GenkitError({
                status: "INTERNAL",
                message: `Failed to create cache: ${cacheError}`
            });
        }
    }
    if (!cache) {
        throw new import_genkit.GenkitError({
            status: "INTERNAL",
            message: "Failed to use context cache feature"
        });
    }
    return {
        cache,
        newChatRequest
    };
}
async function handleCacheIfNeeded(apiKey, request, chatRequest, modelVersion, cacheConfigDetails) {
    if (!cacheConfigDetails || !(0, import_utils.validateContextCacheRequest)(request, modelVersion)) {
        return {
            chatRequest,
            cache: null
        };
    }
    const { cache, newChatRequest } = await handleContextCache(apiKey, request, chatRequest, modelVersion, cacheConfigDetails);
    return {
        chatRequest: newChatRequest,
        cache
    };
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    handleCacheIfNeeded,
    handleContextCache
}); //# sourceMappingURL=index.js.map
}}),
"[project]/node_modules/@genkit-ai/googleai/lib/gemini.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var gemini_exports = {};
__export(gemini_exports, {
    GENERIC_GEMINI_MODEL: ()=>GENERIC_GEMINI_MODEL,
    GeminiConfigSchema: ()=>GeminiConfigSchema,
    GeminiGemmaConfigSchema: ()=>GeminiGemmaConfigSchema,
    GeminiTtsConfigSchema: ()=>GeminiTtsConfigSchema,
    SUPPORTED_GEMINI_MODELS: ()=>SUPPORTED_GEMINI_MODELS,
    aggregateResponses: ()=>aggregateResponses,
    cleanSchema: ()=>cleanSchema,
    defineGoogleAIModel: ()=>defineGoogleAIModel,
    fromGeminiCandidate: ()=>fromGeminiCandidate,
    gemini: ()=>gemini,
    gemini10Pro: ()=>gemini10Pro,
    gemini15Flash: ()=>gemini15Flash,
    gemini15Flash8b: ()=>gemini15Flash8b,
    gemini15Pro: ()=>gemini15Pro,
    gemini20Flash: ()=>gemini20Flash,
    gemini20FlashExp: ()=>gemini20FlashExp,
    gemini20FlashLite: ()=>gemini20FlashLite,
    gemini20ProExp0205: ()=>gemini20ProExp0205,
    gemini25Flash: ()=>gemini25Flash,
    gemini25FlashPreview0417: ()=>gemini25FlashPreview0417,
    gemini25FlashPreviewTts: ()=>gemini25FlashPreviewTts,
    gemini25Pro: ()=>gemini25Pro,
    gemini25ProExp0325: ()=>gemini25ProExp0325,
    gemini25ProPreview0325: ()=>gemini25ProPreview0325,
    gemini25ProPreviewTts: ()=>gemini25ProPreviewTts,
    gemma312bit: ()=>gemma312bit,
    gemma31bit: ()=>gemma31bit,
    gemma327bit: ()=>gemma327bit,
    gemma34bit: ()=>gemma34bit,
    gemma3ne4bit: ()=>gemma3ne4bit,
    toGeminiMessage: ()=>toGeminiMessage,
    toGeminiSystemInstruction: ()=>toGeminiSystemInstruction,
    toGeminiTool: ()=>toGeminiTool
});
module.exports = __toCommonJS(gemini_exports);
var import_generative_ai = __turbopack_context__.r("[project]/node_modules/@google/generative-ai/dist/index.js [app-rsc] (ecmascript)");
var import_genkit = __turbopack_context__.r("[project]/node_modules/genkit/lib/index.js [app-rsc] (ecmascript)");
var import_model = __turbopack_context__.r("[project]/node_modules/genkit/lib/model.js [app-rsc] (ecmascript)");
var import_middleware = __turbopack_context__.r("[project]/node_modules/genkit/lib/middleware.js [app-rsc] (ecmascript)");
var import_tracing = __turbopack_context__.r("[project]/node_modules/genkit/lib/tracing.js [app-rsc] (ecmascript)");
var import_common = __turbopack_context__.r("[project]/node_modules/@genkit-ai/googleai/lib/common.js [app-rsc] (ecmascript)");
var import_context_caching = __turbopack_context__.r("[project]/node_modules/@genkit-ai/googleai/lib/context-caching/index.js [app-rsc] (ecmascript)");
var import_utils = __turbopack_context__.r("[project]/node_modules/@genkit-ai/googleai/lib/context-caching/utils.js [app-rsc] (ecmascript)");
const SafetySettingsSchema = import_genkit.z.object({
    category: import_genkit.z.enum([
        "HARM_CATEGORY_UNSPECIFIED",
        "HARM_CATEGORY_HATE_SPEECH",
        "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        "HARM_CATEGORY_HARASSMENT",
        "HARM_CATEGORY_DANGEROUS_CONTENT",
        "HARM_CATEGORY_CIVIC_INTEGRITY"
    ]),
    threshold: import_genkit.z.enum([
        "BLOCK_LOW_AND_ABOVE",
        "BLOCK_MEDIUM_AND_ABOVE",
        "BLOCK_ONLY_HIGH",
        "BLOCK_NONE"
    ])
});
const VoiceConfigSchema = import_genkit.z.object({
    prebuiltVoiceConfig: import_genkit.z.object({
        // TODO: Make this an array of objects so we can also specify the description
        // for each voiceName.
        voiceName: import_genkit.z.union([
            import_genkit.z.enum([
                "Zephyr",
                "Puck",
                "Charon",
                "Kore",
                "Fenrir",
                "Leda",
                "Orus",
                "Aoede",
                "Callirrhoe",
                "Autonoe",
                "Enceladus",
                "Iapetus",
                "Umbriel",
                "Algieba",
                "Despina",
                "Erinome",
                "Algenib",
                "Rasalgethi",
                "Laomedeia",
                "Achernar",
                "Alnilam",
                "Schedar",
                "Gacrux",
                "Pulcherrima",
                "Achird",
                "Zubenelgenubi",
                "Vindemiatrix",
                "Sadachbia",
                "Sadaltager",
                "Sulafat"
            ]),
            // To allow any new string values
            import_genkit.z.string()
        ]).describe("Name of the preset voice to use").optional()
    }).describe("Configuration for the prebuilt speaker to use").passthrough().optional()
}).describe("Configuration for the voice to use").passthrough();
const GeminiConfigSchema = import_model.GenerationCommonConfigSchema.extend({
    temperature: import_genkit.z.number().min(0).max(2).describe(import_model.GenerationCommonConfigDescriptions.temperature + " The default value is 1.0.").optional(),
    topP: import_genkit.z.number().min(0).max(1).describe(import_model.GenerationCommonConfigDescriptions.topP + " The default value is 0.95.").optional(),
    apiKey: import_genkit.z.string().describe("Overrides the plugin-configured API key, if specified.").optional(),
    safetySettings: import_genkit.z.array(SafetySettingsSchema).describe("Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.").optional(),
    codeExecution: import_genkit.z.union([
        import_genkit.z.boolean(),
        import_genkit.z.object({}).strict()
    ]).describe("Enables the model to generate and run code.").optional(),
    contextCache: import_genkit.z.boolean().describe("Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.").optional(),
    functionCallingConfig: import_genkit.z.object({
        mode: import_genkit.z.enum([
            "MODE_UNSPECIFIED",
            "AUTO",
            "ANY",
            "NONE"
        ]).optional(),
        allowedFunctionNames: import_genkit.z.array(import_genkit.z.string()).optional()
    }).describe("Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.").optional(),
    responseModalities: import_genkit.z.array(import_genkit.z.enum([
        "TEXT",
        "IMAGE",
        "AUDIO"
    ])).describe("The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.").optional(),
    googleSearchRetrieval: import_genkit.z.union([
        import_genkit.z.boolean(),
        import_genkit.z.object({}).passthrough()
    ]).describe("Retrieve public web data for grounding, powered by Google Search.").optional()
}).passthrough();
const GeminiGemmaConfigSchema = GeminiConfigSchema.extend({
    temperature: import_genkit.z.number().min(0).max(1).describe(import_model.GenerationCommonConfigDescriptions.temperature + " The default value is 1.0.").optional()
}).passthrough();
const GeminiTtsConfigSchema = GeminiConfigSchema.extend({
    speechConfig: import_genkit.z.object({
        voiceConfig: VoiceConfigSchema.optional(),
        multiSpeakerVoiceConfig: import_genkit.z.object({
            speakerVoiceConfigs: import_genkit.z.array(import_genkit.z.object({
                speaker: import_genkit.z.string().describe("Name of the speaker to use"),
                voiceConfig: VoiceConfigSchema
            }).describe("Configuration for a single speaker in a multi speaker setup").passthrough()).describe("Configuration for all the enabled speaker voices")
        }).describe("Configuration for multi-speaker setup").passthrough().optional()
    }).describe("Speech generation config").passthrough().optional()
}).passthrough();
const gemini10Pro = (0, import_model.modelRef)({
    name: "googleai/gemini-1.0-pro",
    info: {
        label: "Google AI - Gemini Pro",
        versions: [
            "gemini-pro",
            "gemini-1.0-pro-latest",
            "gemini-1.0-pro-001"
        ],
        supports: {
            multiturn: true,
            media: false,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiConfigSchema
});
const gemini15Pro = (0, import_model.modelRef)({
    name: "googleai/gemini-1.5-pro",
    info: {
        label: "Google AI - Gemini 1.5 Pro",
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        },
        versions: [
            "gemini-1.5-pro-latest",
            "gemini-1.5-pro-001",
            "gemini-1.5-pro-002"
        ]
    },
    configSchema: GeminiConfigSchema
});
const gemini15Flash = (0, import_model.modelRef)({
    name: "googleai/gemini-1.5-flash",
    info: {
        label: "Google AI - Gemini 1.5 Flash",
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools",
            // @ts-ignore
            contextCache: true
        },
        versions: [
            "gemini-1.5-flash-latest",
            "gemini-1.5-flash-001",
            "gemini-1.5-flash-002"
        ]
    },
    configSchema: GeminiConfigSchema
});
const gemini15Flash8b = (0, import_model.modelRef)({
    name: "googleai/gemini-1.5-flash-8b",
    info: {
        label: "Google AI - Gemini 1.5 Flash",
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        },
        versions: [
            "gemini-1.5-flash-8b-latest",
            "gemini-1.5-flash-8b-001"
        ]
    },
    configSchema: GeminiConfigSchema
});
const gemini20Flash = (0, import_model.modelRef)({
    name: "googleai/gemini-2.0-flash",
    info: {
        label: "Google AI - Gemini 2.0 Flash",
        versions: [],
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiConfigSchema
});
const gemini20FlashExp = (0, import_model.modelRef)({
    name: "googleai/gemini-2.0-flash-exp",
    info: {
        label: "Google AI - Gemini 2.0 Flash (Experimental)",
        versions: [],
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiConfigSchema
});
const gemini20FlashLite = (0, import_model.modelRef)({
    name: "googleai/gemini-2.0-flash-lite",
    info: {
        label: "Google AI - Gemini 2.0 Flash Lite",
        versions: [],
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiConfigSchema
});
const gemini20ProExp0205 = (0, import_model.modelRef)({
    name: "googleai/gemini-2.0-pro-exp-02-05",
    info: {
        label: "Google AI - Gemini 2.0 Pro Exp 02-05",
        versions: [],
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiConfigSchema
});
const gemini25FlashPreview0417 = (0, import_model.modelRef)({
    name: "googleai/gemini-2.5-flash-preview-04-17",
    info: {
        label: "Google AI - Gemini 2.5 Flash Preview 04-17",
        versions: [],
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiConfigSchema
});
const gemini25FlashPreviewTts = (0, import_model.modelRef)({
    name: "googleai/gemini-2.5-flash-preview-tts",
    info: {
        label: "Google AI - Gemini 2.5 Flash Preview TTS",
        versions: [],
        supports: {
            multiturn: false,
            media: false,
            tools: false,
            toolChoice: false,
            systemRole: false,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiTtsConfigSchema
});
const gemini25ProExp0325 = (0, import_model.modelRef)({
    name: "googleai/gemini-2.5-pro-exp-03-25",
    info: {
        label: "Google AI - Gemini 2.5 Pro Exp 03-25",
        versions: [],
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiConfigSchema
});
const gemini25ProPreview0325 = (0, import_model.modelRef)({
    name: "googleai/gemini-2.5-pro-preview-03-25",
    info: {
        label: "Google AI - Gemini 2.5 Pro Preview 03-25",
        versions: [],
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiConfigSchema
});
const gemini25ProPreviewTts = (0, import_model.modelRef)({
    name: "googleai/gemini-2.5-pro-preview-tts",
    info: {
        label: "Google AI - Gemini 2.5 Pro Preview TTS",
        versions: [],
        supports: {
            multiturn: false,
            media: false,
            tools: false,
            toolChoice: false,
            systemRole: false,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiTtsConfigSchema
});
const gemini25Pro = (0, import_model.modelRef)({
    name: "googleai/gemini-2.5-pro",
    info: {
        label: "Google AI - Gemini 2.5 Pro",
        versions: [],
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiConfigSchema
});
const gemini25Flash = (0, import_model.modelRef)({
    name: "googleai/gemini-2.5-flash",
    info: {
        label: "Google AI - Gemini 2.5 Flash",
        versions: [],
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiConfigSchema
});
const gemma312bit = (0, import_model.modelRef)({
    name: "googleai/gemma-3-12b-it",
    info: {
        label: "Google AI - Gemma 3 12B",
        versions: [],
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiGemmaConfigSchema
});
const gemma31bit = (0, import_model.modelRef)({
    name: "googleai/gemma-3-1b-it",
    info: {
        label: "Google AI - Gemma 3 1B",
        versions: [],
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiGemmaConfigSchema
});
const gemma327bit = (0, import_model.modelRef)({
    name: "googleai/gemma-3-27b-it",
    info: {
        label: "Google AI - Gemma 3 27B",
        versions: [],
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiGemmaConfigSchema
});
const gemma34bit = (0, import_model.modelRef)({
    name: "googleai/gemma-3-4b-it",
    info: {
        label: "Google AI - Gemma 3 4B",
        versions: [],
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiGemmaConfigSchema
});
const gemma3ne4bit = (0, import_model.modelRef)({
    name: "googleai/gemma-3n-e4b-it",
    info: {
        label: "Google AI - Gemma 3n E4B",
        versions: [],
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        }
    },
    configSchema: GeminiGemmaConfigSchema
});
const SUPPORTED_GEMINI_MODELS = {
    "gemini-1.5-pro": gemini15Pro,
    "gemini-1.5-flash": gemini15Flash,
    "gemini-1.5-flash-8b": gemini15Flash8b,
    "gemini-2.0-pro-exp-02-05": gemini20ProExp0205,
    "gemini-2.0-flash": gemini20Flash,
    "gemini-2.0-flash-lite": gemini20FlashLite,
    "gemini-2.0-flash-exp": gemini20FlashExp,
    "gemini-2.5-pro-exp-03-25": gemini25ProExp0325,
    "gemini-2.5-pro-preview-03-25": gemini25ProPreview0325,
    "gemini-2.5-pro-preview-tts": gemini25ProPreviewTts,
    "gemini-2.5-flash-preview-04-17": gemini25FlashPreview0417,
    "gemini-2.5-flash-preview-tts": gemini25FlashPreviewTts,
    "gemini-2.5-flash": gemini25Flash,
    "gemini-2.5-pro": gemini25Pro,
    "gemma-3-12b-it": gemma312bit,
    "gemma-3-1b-it": gemma31bit,
    "gemma-3-27b-it": gemma327bit,
    "gemma-3-4b-it": gemma34bit,
    "gemma-3n-e4b-it": gemma3ne4bit
};
const GENERIC_GEMINI_MODEL = (0, import_model.modelRef)({
    name: "googleai/gemini",
    configSchema: GeminiConfigSchema,
    info: {
        label: "Google Gemini",
        supports: {
            multiturn: true,
            media: true,
            tools: true,
            toolChoice: true,
            systemRole: true,
            constrained: "no-tools"
        }
    }
});
function longestMatchingPrefix(version, potentialMatches) {
    return potentialMatches.filter((p)=>version.startsWith(p)).reduce((longest, current)=>current.length > longest.length ? current : longest, "");
}
function gemini(version, options = {}) {
    const nearestModel = nearestGeminiModelRef(version);
    return (0, import_model.modelRef)({
        name: `googleai/${version}`,
        config: options,
        configSchema: GeminiConfigSchema,
        info: {
            ...nearestModel.info,
            // If exact suffix match for a known model, use its label, otherwise create a new label
            label: nearestModel.name.endsWith(version) ? nearestModel.info?.label : `Google AI - ${version}`
        }
    });
}
function nearestGeminiModelRef(version, options = {}) {
    const matchingKey = longestMatchingPrefix(version, Object.keys(SUPPORTED_GEMINI_MODELS));
    if (matchingKey) {
        return SUPPORTED_GEMINI_MODELS[matchingKey].withConfig({
            ...options,
            version
        });
    }
    return GENERIC_GEMINI_MODEL.withConfig({
        ...options,
        version
    });
}
function toGeminiRole(role, model) {
    switch(role){
        case "user":
            return "user";
        case "model":
            return "model";
        case "system":
            if (model?.info?.supports?.systemRole) {
                throw new Error("system role is only supported for a single message in the first position");
            } else {
                throw new Error("system role is not supported");
            }
        case "tool":
            return "function";
        default:
            return "user";
    }
}
function convertSchemaProperty(property) {
    if (!property || !property.type) {
        return void 0;
    }
    const baseSchema = {};
    if (property.description) {
        baseSchema.description = property.description;
    }
    if (property.enum) {
        baseSchema.type = import_generative_ai.SchemaType.STRING;
        baseSchema.enum = property.enum;
    }
    if (property.nullable) {
        baseSchema.nullable = property.nullable;
    }
    let propertyType;
    if (Array.isArray(property.type)) {
        const types = property.type;
        if (types.includes("null")) {
            baseSchema.nullable = true;
        }
        propertyType = types.find((t)=>t !== "null");
    } else {
        propertyType = property.type;
    }
    if (propertyType === "object") {
        const nestedProperties = {};
        Object.keys(property.properties ?? {}).forEach((key)=>{
            nestedProperties[key] = convertSchemaProperty(property.properties[key]);
        });
        return {
            ...baseSchema,
            type: import_generative_ai.SchemaType.OBJECT,
            properties: nestedProperties,
            required: property.required
        };
    } else if (propertyType === "array") {
        return {
            ...baseSchema,
            type: import_generative_ai.SchemaType.ARRAY,
            items: convertSchemaProperty(property.items)
        };
    } else {
        const schemaType = import_generative_ai.SchemaType[propertyType.toUpperCase()];
        if (!schemaType) {
            throw new import_genkit.GenkitError({
                status: "INVALID_ARGUMENT",
                message: `Unsupported property type ${propertyType.toUpperCase()}`
            });
        }
        return {
            ...baseSchema,
            type: schemaType
        };
    }
}
function toGeminiTool(tool) {
    const declaration = {
        name: tool.name.replace(/\//g, "__"),
        // Gemini throws on '/' in tool name
        description: tool.description,
        parameters: convertSchemaProperty(tool.inputSchema)
    };
    return declaration;
}
function toInlineData(part) {
    const dataUrl = part.media.url;
    const b64Data = dataUrl.substring(dataUrl.indexOf(",") + 1);
    const contentType = part.media.contentType || dataUrl.substring(dataUrl.indexOf(":") + 1, dataUrl.indexOf(";"));
    return {
        inlineData: {
            mimeType: contentType,
            data: b64Data
        }
    };
}
function toFileData(part) {
    if (!part.media.contentType) throw new Error("Must supply a `contentType` when sending File URIs to Gemini.");
    return {
        fileData: {
            mimeType: part.media.contentType,
            fileUri: part.media.url
        }
    };
}
function fromInlineData(inlinePart) {
    if (!inlinePart.inlineData || !inlinePart.inlineData.hasOwnProperty("mimeType") || !inlinePart.inlineData.hasOwnProperty("data")) {
        throw new Error("Invalid InlineDataPart: missing required properties");
    }
    const { mimeType, data } = inlinePart.inlineData;
    const dataUrl = `data:${mimeType};base64,${data}`;
    return {
        media: {
            url: dataUrl,
            contentType: mimeType
        }
    };
}
function toFunctionCall(part) {
    if (!part?.toolRequest?.input) {
        throw Error("Invalid ToolRequestPart: input was missing.");
    }
    return {
        functionCall: {
            name: part.toolRequest.name,
            args: part.toolRequest.input
        }
    };
}
function fromFunctionCall(part, ref) {
    if (!part.functionCall) {
        throw Error("Invalid FunctionCallPart");
    }
    return {
        toolRequest: {
            name: part.functionCall.name,
            input: part.functionCall.args,
            ref
        }
    };
}
function toFunctionResponse(part) {
    if (!part?.toolResponse?.output) {
        throw Error("Invalid ToolResponsePart: output was missing.");
    }
    return {
        functionResponse: {
            name: part.toolResponse.name,
            response: {
                name: part.toolResponse.name,
                content: part.toolResponse.output
            }
        }
    };
}
function fromFunctionResponse(part) {
    if (!part.functionResponse) {
        throw new Error("Invalid FunctionResponsePart.");
    }
    return {
        toolResponse: {
            name: part.functionResponse.name.replace(/__/g, "/"),
            // restore slashes
            output: part.functionResponse.response
        }
    };
}
function fromExecutableCode(part) {
    if (!part.executableCode) {
        throw new Error("Invalid GeminiPart: missing executableCode");
    }
    return {
        custom: {
            executableCode: {
                language: part.executableCode.language,
                code: part.executableCode.code
            }
        }
    };
}
function fromCodeExecutionResult(part) {
    if (!part.codeExecutionResult) {
        throw new Error("Invalid GeminiPart: missing codeExecutionResult");
    }
    return {
        custom: {
            codeExecutionResult: {
                outcome: part.codeExecutionResult.outcome,
                output: part.codeExecutionResult.output
            }
        }
    };
}
function fromThought(part) {
    return {
        reasoning: part.text || "",
        metadata: {
            thoughtSignature: part.thoughtSignature
        }
    };
}
function toCustomPart(part) {
    if (!part.custom) {
        throw new Error("Invalid GeminiPart: missing custom");
    }
    if (part.custom.codeExecutionResult) {
        return {
            codeExecutionResult: part.custom.codeExecutionResult
        };
    }
    if (part.custom.executableCode) {
        return {
            executableCode: part.custom.executableCode
        };
    }
    throw new Error("Unsupported Custom Part type");
}
function toThought(part) {
    const outPart = {
        thought: true
    };
    if (part.metadata?.thoughtSignature) outPart.thoughtSignature = part.metadata.thoughtSignature;
    if (part.reasoning?.length) outPart.text = part.reasoning;
    return outPart;
}
function toGeminiPart(part) {
    if (part.text !== void 0) return {
        text: part.text || " "
    };
    if (part.media) {
        if (part.media.url.startsWith("data:")) return toInlineData(part);
        return toFileData(part);
    }
    if (part.toolRequest) return toFunctionCall(part);
    if (part.toolResponse) return toFunctionResponse(part);
    if (part.custom) return toCustomPart(part);
    if (typeof part.reasoning === "string") return toThought(part);
    throw new Error("Unsupported Part type" + JSON.stringify(part));
}
function fromGeminiPart(part, jsonMode, ref) {
    if ("thought" in part) return fromThought(part);
    if (typeof part.text === "string") return {
        text: part.text
    };
    if (part.inlineData) return fromInlineData(part);
    if (part.functionCall) return fromFunctionCall(part, ref);
    if (part.functionResponse) return fromFunctionResponse(part);
    if (part.executableCode) return fromExecutableCode(part);
    if (part.codeExecutionResult) return fromCodeExecutionResult(part);
    throw new Error("Unsupported GeminiPart type: " + JSON.stringify(part));
}
function toGeminiMessage(message, model) {
    let sortedParts = message.content;
    if (message.role === "tool") {
        sortedParts = [
            ...message.content
        ].sort((a, b)=>{
            const aRef = a.toolResponse?.ref;
            const bRef = b.toolResponse?.ref;
            if (!aRef && !bRef) return 0;
            if (!aRef) return 1;
            if (!bRef) return -1;
            return Number.parseInt(aRef, 10) - Number.parseInt(bRef, 10);
        });
    }
    return {
        role: toGeminiRole(message.role, model),
        parts: sortedParts.map(toGeminiPart)
    };
}
function toGeminiSystemInstruction(message) {
    return {
        role: "user",
        parts: message.content.map(toGeminiPart)
    };
}
function fromGeminiFinishReason(reason) {
    if (!reason) return "unknown";
    switch(reason){
        case "STOP":
            return "stop";
        case "MAX_TOKENS":
            return "length";
        case "SAFETY":
        // blocked for safety
        case "RECITATION":
            return "blocked";
        default:
            return "unknown";
    }
}
function fromGeminiCandidate(candidate, jsonMode = false) {
    const parts = candidate.content?.parts || [];
    const genkitCandidate = {
        index: candidate.index || 0,
        message: {
            role: "model",
            content: parts.map((part, index)=>fromGeminiPart(part, jsonMode, index.toString()))
        },
        finishReason: fromGeminiFinishReason(candidate.finishReason),
        finishMessage: candidate.finishMessage,
        custom: {
            safetyRatings: candidate.safetyRatings,
            citationMetadata: candidate.citationMetadata
        }
    };
    return genkitCandidate;
}
function cleanSchema(schema) {
    const out = structuredClone(schema);
    for(const key in out){
        if (key === "$schema" || key === "additionalProperties") {
            delete out[key];
            continue;
        }
        if (typeof out[key] === "object") {
            out[key] = cleanSchema(out[key]);
        }
        if (key === "type" && Array.isArray(out[key])) {
            out[key] = out[key].find((t)=>t !== "null");
        }
    }
    return out;
}
function defineGoogleAIModel({ ai, name, apiKey: apiKeyOption, apiVersion, baseUrl, info, defaultConfig, debugTraces }) {
    let apiKey;
    if (apiKeyOption !== false) {
        apiKey = apiKeyOption || (0, import_common.getApiKeyFromEnvVar)();
        if (!apiKey) {
            throw new import_genkit.GenkitError({
                status: "FAILED_PRECONDITION",
                message: "Please pass in the API key or set the GEMINI_API_KEY or GOOGLE_API_KEY environment variable.\nFor more details see https://genkit.dev/docs/plugins/google-genai"
            });
        }
    }
    const apiModelName = name.startsWith("googleai/") ? name.substring("googleai/".length) : name;
    const model = SUPPORTED_GEMINI_MODELS[apiModelName] ?? (0, import_model.modelRef)({
        name: `googleai/${apiModelName}`,
        info: {
            label: `Google AI - ${apiModelName}`,
            supports: {
                multiturn: true,
                media: true,
                tools: true,
                systemRole: true,
                output: [
                    "text",
                    "json"
                ]
            },
            ...info
        },
        configSchema: GeminiConfigSchema
    });
    const middleware = [];
    if (model.info?.supports?.media) {
        middleware.push((0, import_middleware.downloadRequestMedia)({
            maxBytes: 1024 * 1024 * 10,
            // don't downlaod files that have been uploaded using the Files API
            filter: (part)=>{
                try {
                    const url = new URL(part.media.url);
                    if (// Gemini can handle these URLs
                    [
                        "generativelanguage.googleapis.com",
                        "www.youtube.com",
                        "youtube.com",
                        "youtu.be"
                    ].includes(url.hostname)) return false;
                } catch  {}
                return true;
            }
        }));
    }
    return ai.defineModel({
        apiVersion: "v2",
        name: model.name,
        ...model.info,
        configSchema: model.configSchema,
        use: middleware
    }, async (request, { streamingRequested, sendChunk, abortSignal })=>{
        const options = {
            apiClient: import_genkit.GENKIT_CLIENT_HEADER
        };
        if (apiVersion) {
            options.apiVersion = apiVersion;
        }
        if (apiVersion) {
            options.baseUrl = baseUrl;
        }
        const requestConfig = {
            ...defaultConfig,
            ...request.config
        };
        const messages = [
            ...request.messages
        ];
        if (messages.length === 0) throw new Error("No messages provided.");
        let systemInstruction = void 0;
        if (model.info?.supports?.systemRole) {
            const systemMessage = messages.find((m)=>m.role === "system");
            if (systemMessage) {
                messages.splice(messages.indexOf(systemMessage), 1);
                systemInstruction = toGeminiSystemInstruction(systemMessage);
            }
        }
        const tools = [];
        if (request.tools?.length) {
            tools.push({
                functionDeclarations: request.tools.map(toGeminiTool)
            });
        }
        const { apiKey: apiKeyFromConfig, safetySettings: safetySettingsFromConfig, codeExecution: codeExecutionFromConfig, version: versionFromConfig, functionCallingConfig, googleSearchRetrieval, tools: toolsFromConfig, ...restOfConfigOptions } = requestConfig;
        if (codeExecutionFromConfig) {
            tools.push({
                codeExecution: request.config.codeExecution === true ? {} : request.config.codeExecution
            });
        }
        if (toolsFromConfig) {
            tools.push(...toolsFromConfig);
        }
        if (googleSearchRetrieval) {
            tools.push({
                googleSearch: googleSearchRetrieval === true ? {} : googleSearchRetrieval
            });
        }
        let toolConfig;
        if (functionCallingConfig) {
            toolConfig = {
                functionCallingConfig: {
                    allowedFunctionNames: functionCallingConfig.allowedFunctionNames,
                    mode: toFunctionModeEnum(functionCallingConfig.mode)
                }
            };
        } else if (request.toolChoice) {
            toolConfig = {
                functionCallingConfig: {
                    mode: toGeminiFunctionModeEnum(request.toolChoice)
                }
            };
        }
        const jsonMode = request.output?.format === "json" || request.output?.contentType === "application/json" && tools.length === 0;
        const generationConfig = {
            ...restOfConfigOptions,
            candidateCount: request.candidates || void 0,
            responseMimeType: jsonMode ? "application/json" : void 0
        };
        if (request.output?.constrained && jsonMode) {
            generationConfig.responseSchema = cleanSchema(request.output.schema);
        }
        const msg = toGeminiMessage(messages[messages.length - 1], model);
        const fromJSONModeScopedGeminiCandidate = (candidate)=>{
            return fromGeminiCandidate(candidate, jsonMode);
        };
        const chatRequest = {
            systemInstruction,
            generationConfig,
            tools: tools.length ? tools : void 0,
            toolConfig,
            history: messages.slice(0, -1).map((message)=>toGeminiMessage(message, model)),
            safetySettings: safetySettingsFromConfig
        };
        const modelVersion = versionFromConfig || model.version || apiModelName;
        const cacheConfigDetails = (0, import_utils.extractCacheConfig)(request);
        const { chatRequest: updatedChatRequest, cache } = await (0, import_context_caching.handleCacheIfNeeded)(apiKey, request, chatRequest, modelVersion, cacheConfigDetails);
        if (!apiKeyFromConfig && !apiKey) {
            throw new import_genkit.GenkitError({
                status: "INVALID_ARGUMENT",
                message: "GoogleAI plugin was initialized with {apiKey: false} but no apiKey configuration was passed at call time."
            });
        }
        const client = new import_generative_ai.GoogleGenerativeAI(apiKeyFromConfig || apiKey);
        let genModel;
        if (cache) {
            genModel = client.getGenerativeModelFromCachedContent(cache, {
                model: modelVersion
            }, options);
        } else {
            genModel = client.getGenerativeModel({
                model: modelVersion
            }, options);
        }
        const callGemini = async ()=>{
            let response;
            if (streamingRequested) {
                const result = await genModel.startChat(updatedChatRequest).sendMessageStream(msg.parts, {
                    ...options,
                    signal: abortSignal
                });
                const chunks = [];
                for await (const item of result.stream){
                    chunks.push(item);
                    item.candidates?.forEach((candidate)=>{
                        const c = fromJSONModeScopedGeminiCandidate(candidate);
                        sendChunk({
                            index: c.index,
                            content: c.message.content
                        });
                    });
                }
                response = aggregateResponses(chunks);
            } else {
                const result = await genModel.startChat(updatedChatRequest).sendMessage(msg.parts, {
                    ...options,
                    signal: abortSignal
                });
                response = result.response;
            }
            const candidates = response.candidates || [];
            if (response.candidates?.["undefined"]) {
                candidates.push(response.candidates["undefined"]);
            }
            if (!candidates.length) {
                throw new import_genkit.GenkitError({
                    status: "FAILED_PRECONDITION",
                    message: "No valid candidates returned."
                });
            }
            const candidateData = candidates.map(fromJSONModeScopedGeminiCandidate) || [];
            return {
                candidates: candidateData,
                custom: response,
                usage: {
                    ...(0, import_model.getBasicUsageStats)(request.messages, candidateData),
                    inputTokens: response.usageMetadata?.promptTokenCount,
                    outputTokens: response.usageMetadata?.candidatesTokenCount,
                    totalTokens: response.usageMetadata?.totalTokenCount,
                    cachedContentTokens: response.usageMetadata?.cachedContentTokenCount
                }
            };
        };
        return debugTraces ? await (0, import_tracing.runInNewSpan)(ai.registry, {
            metadata: {
                name: streamingRequested ? "sendMessageStream" : "sendMessage"
            }
        }, async (metadata)=>{
            metadata.input = {
                sdk: "@google/generative-ai",
                cache,
                model: genModel.model,
                chatOptions: updatedChatRequest,
                parts: msg.parts,
                options
            };
            const response = await callGemini();
            metadata.output = response.custom;
            return response;
        }) : await callGemini();
    });
}
function toFunctionModeEnum(configEnum) {
    if (configEnum === void 0) {
        return void 0;
    }
    switch(configEnum){
        case "MODE_UNSPECIFIED":
            {
                return import_generative_ai.FunctionCallingMode.MODE_UNSPECIFIED;
            }
        case "ANY":
            {
                return import_generative_ai.FunctionCallingMode.ANY;
            }
        case "AUTO":
            {
                return import_generative_ai.FunctionCallingMode.AUTO;
            }
        case "NONE":
            {
                return import_generative_ai.FunctionCallingMode.NONE;
            }
        default:
            throw new Error(`unsupported function calling mode: ${configEnum}`);
    }
}
function toGeminiFunctionModeEnum(genkitMode) {
    if (genkitMode === void 0) {
        return void 0;
    }
    switch(genkitMode){
        case "required":
            {
                return import_generative_ai.FunctionCallingMode.ANY;
            }
        case "auto":
            {
                return import_generative_ai.FunctionCallingMode.AUTO;
            }
        case "none":
            {
                return import_generative_ai.FunctionCallingMode.NONE;
            }
        default:
            throw new Error(`unsupported function calling mode: ${genkitMode}`);
    }
}
function aggregateResponses(responses) {
    const lastResponse = responses[responses.length - 1];
    const aggregatedResponse = {
        promptFeedback: lastResponse?.promptFeedback
    };
    for (const response of responses){
        if (response.candidates) {
            let candidateIndex = 0;
            for (const candidate of response.candidates){
                if (!aggregatedResponse.candidates) {
                    aggregatedResponse.candidates = [];
                }
                if (!aggregatedResponse.candidates[candidateIndex]) {
                    aggregatedResponse.candidates[candidateIndex] = {
                        index: candidateIndex
                    };
                }
                aggregatedResponse.candidates[candidateIndex].citationMetadata = candidate.citationMetadata;
                aggregatedResponse.candidates[candidateIndex].groundingMetadata = candidate.groundingMetadata;
                aggregatedResponse.candidates[candidateIndex].finishReason = candidate.finishReason;
                aggregatedResponse.candidates[candidateIndex].finishMessage = candidate.finishMessage;
                aggregatedResponse.candidates[candidateIndex].safetyRatings = candidate.safetyRatings;
                if (candidate.content && candidate.content.parts) {
                    if (!aggregatedResponse.candidates[candidateIndex].content) {
                        aggregatedResponse.candidates[candidateIndex].content = {
                            role: candidate.content.role || "user",
                            parts: []
                        };
                    }
                    for (const part of candidate.content.parts){
                        const newPart = {};
                        if (part.text) {
                            newPart.text = part.text;
                        }
                        if (part.functionCall) {
                            newPart.functionCall = part.functionCall;
                        }
                        if (part.executableCode) {
                            newPart.executableCode = part.executableCode;
                        }
                        if (part.codeExecutionResult) {
                            newPart.codeExecutionResult = part.codeExecutionResult;
                        }
                        if (Object.keys(newPart).length === 0) {
                            newPart.text = "";
                        }
                        aggregatedResponse.candidates[candidateIndex].content.parts.push(newPart);
                    }
                }
            }
            candidateIndex++;
        }
        if (response.usageMetadata) {
            aggregatedResponse.usageMetadata = response.usageMetadata;
        }
    }
    return aggregatedResponse;
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    GENERIC_GEMINI_MODEL,
    GeminiConfigSchema,
    GeminiGemmaConfigSchema,
    GeminiTtsConfigSchema,
    SUPPORTED_GEMINI_MODELS,
    aggregateResponses,
    cleanSchema,
    defineGoogleAIModel,
    fromGeminiCandidate,
    gemini,
    gemini10Pro,
    gemini15Flash,
    gemini15Flash8b,
    gemini15Pro,
    gemini20Flash,
    gemini20FlashExp,
    gemini20FlashLite,
    gemini20ProExp0205,
    gemini25Flash,
    gemini25FlashPreview0417,
    gemini25FlashPreviewTts,
    gemini25Pro,
    gemini25ProExp0325,
    gemini25ProPreview0325,
    gemini25ProPreviewTts,
    gemma312bit,
    gemma31bit,
    gemma327bit,
    gemma34bit,
    gemma3ne4bit,
    toGeminiMessage,
    toGeminiSystemInstruction,
    toGeminiTool
}); //# sourceMappingURL=gemini.js.map
}}),
"[project]/node_modules/@genkit-ai/googleai/lib/predict.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toESM = (mod, isNodeMode, target)=>(target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(// If the importer is in node compatibility mode or this is not an ESM
    // file that has been converted to a CommonJS file using a Babel-
    // compatible transform (i.e. "__esModule" has not been set), then set
    // "default" to the CommonJS "module.exports" for node compatibility.
    isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", {
        value: mod,
        enumerable: true
    }) : target, mod));
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var predict_exports = {};
__export(predict_exports, {
    checkOp: ()=>checkOp,
    predictModel: ()=>predictModel
});
module.exports = __toCommonJS(predict_exports);
var import_genkit = __turbopack_context__.r("[project]/node_modules/genkit/lib/index.js [app-rsc] (ecmascript)");
function predictEndpoint(options) {
    return `https://generativelanguage.googleapis.com/${options.apiVersion}/models/${options.model}:${options.method}?key=${options.apiKey}`;
}
function opCheckEndpoint(options) {
    return `https://generativelanguage.googleapis.com/${options.apiVersion}/${options.operation}?key=${options.apiKey}`;
}
function predictModel(model, apiKey, method) {
    return async (instances, parameters)=>{
        const fetch = (await __turbopack_context__.r("[project]/node_modules/node-fetch/src/index.js [app-rsc] (ecmascript, async loader)")(__turbopack_context__.i)).default;
        const req = {
            instances,
            parameters
        };
        const response = await fetch(predictEndpoint({
            model,
            apiVersion: "v1beta",
            apiKey,
            method
        }), {
            method: "POST",
            body: JSON.stringify(req),
            headers: {
                "Content-Type": "application/json",
                "X-Goog-Api-Client": import_genkit.GENKIT_CLIENT_HEADER
            }
        });
        if (!response.ok) {
            throw new Error(`Error from Gemini AI predict: HTTP ${response.status}: ${await response.text()}`);
        }
        return await response.json();
    };
}
async function checkOp(operation, apiKey) {
    const fetch = (await __turbopack_context__.r("[project]/node_modules/node-fetch/src/index.js [app-rsc] (ecmascript, async loader)")(__turbopack_context__.i)).default;
    const response = await fetch(opCheckEndpoint({
        apiVersion: "v1beta",
        operation,
        apiKey
    }), {
        method: "GET",
        headers: {
            "Content-Type": "application/json",
            "X-Goog-Api-Client": import_genkit.GENKIT_CLIENT_HEADER
        }
    });
    if (!response.ok) {
        throw new Error(`Error from operation API: HTTP ${response.status}: ${await response.text()}`);
    }
    return await response.json();
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    checkOp,
    predictModel
}); //# sourceMappingURL=predict.js.map
}}),
"[project]/node_modules/@genkit-ai/googleai/lib/imagen.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var imagen_exports = {};
__export(imagen_exports, {
    GENERIC_IMAGEN_INFO: ()=>GENERIC_IMAGEN_INFO,
    ImagenConfigSchema: ()=>ImagenConfigSchema,
    defineImagenModel: ()=>defineImagenModel
});
module.exports = __toCommonJS(imagen_exports);
var import_genkit = __turbopack_context__.r("[project]/node_modules/genkit/lib/index.js [app-rsc] (ecmascript)");
var import_model = __turbopack_context__.r("[project]/node_modules/genkit/lib/model.js [app-rsc] (ecmascript)");
var import_common = __turbopack_context__.r("[project]/node_modules/@genkit-ai/googleai/lib/common.js [app-rsc] (ecmascript)");
var import_predict = __turbopack_context__.r("[project]/node_modules/@genkit-ai/googleai/lib/predict.js [app-rsc] (ecmascript)");
const ImagenConfigSchema = import_genkit.z.object({
    numberOfImages: import_genkit.z.number().describe("The number of images to generate, from 1 to 4 (inclusive). The default is 1.").optional(),
    aspectRatio: import_genkit.z.enum([
        "1:1",
        "9:16",
        "16:9",
        "3:4",
        "4:3"
    ]).describe("Desired aspect ratio of the output image.").optional(),
    personGeneration: import_genkit.z.enum([
        "dont_allow",
        "allow_adult",
        "allow_all"
    ]).describe("Control if/how images of people will be generated by the model.").optional()
}).passthrough();
function toParameters(request) {
    const out = {
        sampleCount: request.config?.numberOfImages ?? 1,
        ...request?.config
    };
    for(const k in out){
        if (!out[k]) delete out[k];
    }
    return out;
}
function extractText(request) {
    return request.messages.at(-1).content.map((c)=>c.text || "").join("");
}
function extractBaseImage(request) {
    return request.messages.at(-1)?.content.find((p)=>!!p.media)?.media?.url.split(",")[1];
}
const GENERIC_IMAGEN_INFO = {
    label: `Google AI - Generic Imagen`,
    supports: {
        media: true,
        multiturn: false,
        tools: false,
        systemRole: false,
        output: [
            "media"
        ]
    }
};
function defineImagenModel(ai, name, apiKey) {
    if (apiKey !== false) {
        apiKey = apiKey || (0, import_common.getApiKeyFromEnvVar)();
        if (!apiKey) {
            throw new import_genkit.GenkitError({
                status: "FAILED_PRECONDITION",
                message: "Please pass in the API key or set the GEMINI_API_KEY or GOOGLE_API_KEY environment variable.\nFor more details see https://genkit.dev/docs/plugins/google-genai"
            });
        }
    }
    const modelName = `googleai/${name}`;
    const model = (0, import_model.modelRef)({
        name: modelName,
        info: {
            ...GENERIC_IMAGEN_INFO,
            label: `Google AI - ${name}`
        },
        configSchema: ImagenConfigSchema
    });
    return ai.defineModel({
        name: modelName,
        ...model.info,
        configSchema: ImagenConfigSchema
    }, async (request)=>{
        const instance = {
            prompt: extractText(request)
        };
        const baseImage = extractBaseImage(request);
        if (baseImage) {
            instance.image = {
                bytesBase64Encoded: baseImage
            };
        }
        const predictClient = (0, import_predict.predictModel)(model.version || name, apiKey, "predict");
        const response = await predictClient([
            instance
        ], toParameters(request));
        if (!response.predictions || response.predictions.length == 0) {
            throw new Error("Model returned no predictions. Possibly due to content filters.");
        }
        const message = {
            role: "model",
            content: []
        };
        response.predictions.forEach((p, i)=>{
            const b64data = p.bytesBase64Encoded;
            const mimeType = p.mimeType;
            message.content.push({
                media: {
                    url: `data:${mimeType};base64,${b64data}`,
                    contentType: mimeType
                }
            });
        });
        return {
            finishReason: "stop",
            message,
            usage: (0, import_model.getBasicUsageStats)(request.messages, message),
            custom: response
        };
    });
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    GENERIC_IMAGEN_INFO,
    ImagenConfigSchema,
    defineImagenModel
}); //# sourceMappingURL=imagen.js.map
}}),
"[project]/node_modules/@genkit-ai/googleai/lib/list-models.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var list_models_exports = {};
__export(list_models_exports, {
    listModels: ()=>listModels
});
module.exports = __toCommonJS(list_models_exports);
async function listModels(baseUrl, apiKey) {
    const res = await fetch(`${baseUrl}/v1beta/models?pageSize=1000&key=${apiKey}`, {
        method: "GET",
        headers: {
            "Content-Type": "application/json"
        }
    });
    const modelResponse = JSON.parse(await res.text());
    return modelResponse.models;
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    listModels
}); //# sourceMappingURL=list-models.js.map
}}),
"[project]/node_modules/@genkit-ai/googleai/lib/veo.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var veo_exports = {};
__export(veo_exports, {
    GENERIC_VEO_INFO: ()=>GENERIC_VEO_INFO,
    VeoConfigSchema: ()=>VeoConfigSchema,
    defineVeoModel: ()=>defineVeoModel
});
module.exports = __toCommonJS(veo_exports);
var import_genkit = __turbopack_context__.r("[project]/node_modules/genkit/lib/index.js [app-rsc] (ecmascript)");
var import_model = __turbopack_context__.r("[project]/node_modules/genkit/lib/model.js [app-rsc] (ecmascript)");
var import_common = __turbopack_context__.r("[project]/node_modules/@genkit-ai/googleai/lib/common.js [app-rsc] (ecmascript)");
var import_predict = __turbopack_context__.r("[project]/node_modules/@genkit-ai/googleai/lib/predict.js [app-rsc] (ecmascript)");
const VeoConfigSchema = import_genkit.z.object({
    // NOTE: Documentation notes numberOfVideos parameter to pick the number of
    // output videos, but this setting does not seem to work
    negativePrompt: import_genkit.z.string().optional(),
    aspectRatio: import_genkit.z.enum([
        "9:16",
        "16:9"
    ]).describe("Desired aspect ratio of the output video.").optional(),
    personGeneration: import_genkit.z.enum([
        "dont_allow",
        "allow_adult",
        "allow_all"
    ]).describe("Control if/how images of people will be generated by the model.").optional(),
    durationSeconds: import_genkit.z.number().step(1).min(5).max(8).describe("Length of each output video in seconds, between 5 and 8.").optional(),
    enhance_prompt: import_genkit.z.boolean().describe("Enable or disable the prompt rewriter. Enabled by default.").optional()
}).passthrough();
function extractText(request) {
    return request.messages.at(-1).content.map((c)=>c.text || "").join("");
}
function toParameters(request) {
    const out = {
        ...request?.config
    };
    for(const k in out){
        if (!out[k]) delete out[k];
    }
    return out;
}
function extractImage(request) {
    const media = request.messages.at(-1)?.content.find((p)=>!!p.media)?.media;
    if (media) {
        const img = media?.url.split(",")[1];
        return {
            bytesBase64Encoded: img,
            mimeType: media.contentType
        };
    }
    return void 0;
}
const GENERIC_VEO_INFO = {
    label: `Google AI - Generic Veo`,
    supports: {
        media: true,
        multiturn: false,
        tools: false,
        systemRole: false,
        output: [
            "media"
        ],
        longRunning: true
    }
};
function defineVeoModel(ai, name, apiKey) {
    if (apiKey !== false) {
        apiKey = apiKey || (0, import_common.getApiKeyFromEnvVar)();
        if (!apiKey) {
            throw new import_genkit.GenkitError({
                status: "FAILED_PRECONDITION",
                message: "Please pass in the API key or set the GEMINI_API_KEY or GOOGLE_API_KEY environment variable.\nFor more details see https://genkit.dev/docs/plugins/google-genai"
            });
        }
    }
    const modelName = `googleai/${name}`;
    const model = (0, import_model.modelRef)({
        name: modelName,
        info: {
            ...GENERIC_VEO_INFO,
            label: `Google AI - ${name}`
        },
        configSchema: VeoConfigSchema
    });
    return ai.defineBackgroundModel({
        name: modelName,
        ...model.info,
        configSchema: VeoConfigSchema,
        async start (request) {
            const instance = {
                prompt: extractText(request)
            };
            const image = extractImage(request);
            if (image) {
                instance.image = image;
            }
            const predictClient = (0, import_predict.predictModel)(model.version || name, apiKey, "predictLongRunning");
            const response = await predictClient([
                instance
            ], toParameters(request));
            return toGenkitOp(response);
        },
        async check (operation) {
            const newOp = await (0, import_predict.checkOp)(operation.id, apiKey);
            return toGenkitOp(newOp);
        }
    });
}
function toGenkitOp(apiOp) {
    const res = {
        id: apiOp.name
    };
    if (apiOp.done !== void 0) {
        res.done = apiOp.done;
    }
    if (apiOp.error) {
        res.error = {
            message: apiOp.error.message
        };
    }
    if (apiOp.response && apiOp.response.generateVideoResponse && apiOp.response.generateVideoResponse.generatedSamples) {
        res.output = {
            finishReason: "stop",
            raw: apiOp.response,
            message: {
                role: "model",
                content: apiOp.response.generateVideoResponse.generatedSamples.map((s)=>{
                    return {
                        media: {
                            url: s.video.uri
                        }
                    };
                })
            }
        };
    }
    return res;
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    GENERIC_VEO_INFO,
    VeoConfigSchema,
    defineVeoModel
}); //# sourceMappingURL=veo.js.map
}}),
"[project]/node_modules/@genkit-ai/googleai/lib/index.mjs [app-rsc] (ecmascript) <locals>": ((__turbopack_context__) => {
"use strict";

var { g: global, __dirname } = __turbopack_context__;
{
__turbopack_context__.s({
    "default": (()=>index_default),
    "googleAI": (()=>googleAI),
    "googleAIPlugin": (()=>googleAIPlugin)
});
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$genkit$2f$lib$2f$index$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$module__evaluation$3e$__ = __turbopack_context__.i("[project]/node_modules/genkit/lib/index.mjs [app-rsc] (ecmascript) <module evaluation>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$genkit$2f$lib$2f$common$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/genkit/lib/common.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$genkit$2f$lib$2f$logging$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$module__evaluation$3e$__ = __turbopack_context__.i("[project]/node_modules/genkit/lib/logging.mjs [app-rsc] (ecmascript) <module evaluation>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$core$2f$lib$2f$logging$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/core/lib/logging.mjs [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$genkit$2f$lib$2f$model$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$module__evaluation$3e$__ = __turbopack_context__.i("[project]/node_modules/genkit/lib/model.mjs [app-rsc] (ecmascript) <module evaluation>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$ai$2f$lib$2f$model$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/ai/lib/model.mjs [app-rsc] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$genkit$2f$lib$2f$plugin$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/genkit/lib/plugin.mjs [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$common$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/googleai/lib/common.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$embedder$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/googleai/lib/embedder.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/googleai/lib/gemini.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$imagen$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/googleai/lib/imagen.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$list$2d$models$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/googleai/lib/list-models.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$veo$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/googleai/lib/veo.js [app-rsc] (ecmascript)");
;
;
;
;
;
;
;
;
;
;
async function initializer(ai, options) {
    let apiVersions = [
        "v1"
    ];
    if (options?.apiVersion) {
        if (Array.isArray(options?.apiVersion)) {
            apiVersions = options?.apiVersion;
        } else {
            apiVersions = [
                options?.apiVersion
            ];
        }
    }
    if (apiVersions.includes("v1beta")) {
        Object.keys(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["SUPPORTED_GEMINI_MODELS"]).forEach((name)=>(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["defineGoogleAIModel"])({
                ai,
                name,
                apiKey: options?.apiKey,
                apiVersion: "v1beta",
                baseUrl: options?.baseUrl,
                debugTraces: options?.experimental_debugTraces
            }));
    }
    if (apiVersions.includes("v1")) {
        Object.keys(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["SUPPORTED_GEMINI_MODELS"]).forEach((name)=>(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["defineGoogleAIModel"])({
                ai,
                name,
                apiKey: options?.apiKey,
                apiVersion: void 0,
                baseUrl: options?.baseUrl,
                debugTraces: options?.experimental_debugTraces
            }));
        Object.keys(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$embedder$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["SUPPORTED_MODELS"]).forEach((name)=>(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$embedder$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["defineGoogleAIEmbedder"])(ai, name, {
                apiKey: options?.apiKey
            }));
    }
    if (options?.models) {
        for (const modelOrRef of options?.models){
            const modelName = typeof modelOrRef === "string" ? modelOrRef : // strip out the `googleai/` prefix
            modelOrRef.name.split("/")[1];
            const modelRef2 = typeof modelOrRef === "string" ? (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["gemini"])(modelOrRef) : modelOrRef;
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["defineGoogleAIModel"])({
                ai,
                name: modelName,
                apiKey: options?.apiKey,
                baseUrl: options?.baseUrl,
                info: {
                    ...modelRef2.info,
                    label: `Google AI - ${modelName}`
                },
                debugTraces: options?.experimental_debugTraces
            });
        }
    }
}
async function resolver(ai, actionType, actionName, options) {
    if (actionType === "embedder") {
        resolveEmbedder(ai, actionName, options);
    } else if (actionName.startsWith("veo")) {
        if (actionType === "background-model") {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$veo$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["defineVeoModel"])(ai, actionName, options?.apiKey);
        }
    } else if (actionType === "model") {
        resolveModel(ai, actionName, options);
    }
}
function resolveModel(ai, actionName, options) {
    if (actionName.startsWith("imagen")) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$imagen$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["defineImagenModel"])(ai, actionName, options?.apiKey);
        return;
    }
    const modelRef2 = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["gemini"])(actionName);
    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["defineGoogleAIModel"])({
        ai,
        name: modelRef2.name,
        apiKey: options?.apiKey,
        baseUrl: options?.baseUrl,
        info: {
            ...modelRef2.info,
            label: `Google AI - ${actionName}`
        },
        debugTraces: options?.experimental_debugTraces
    });
}
function resolveEmbedder(ai, actionName, options) {
    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$embedder$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["defineGoogleAIEmbedder"])(ai, `googleai/${actionName}`, {
        apiKey: options?.apiKey
    });
}
async function listActions(options) {
    const apiKey = options?.apiKey || (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$common$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["getApiKeyFromEnvVar"])();
    if (!apiKey) {
        __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$core$2f$lib$2f$logging$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["logger"].error("Pass in the API key or set the GEMINI_API_KEY or GOOGLE_API_KEY environment variable.");
        return [];
    }
    const models = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$list$2d$models$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["listModels"])(options?.baseUrl || "https://generativelanguage.googleapis.com", apiKey);
    return [
        // Imagen
        ...models.filter((m)=>m.supportedGenerationMethods.includes("predict") && m.name.includes("imagen")).filter((m)=>!m.description || !m.description.includes("deprecated")).map((m)=>{
            const name = m.name.split("/").at(-1);
            return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$genkit$2f$lib$2f$common$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["modelActionMetadata"])({
                name: `googleai/${name}`,
                info: {
                    ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$imagen$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["GENERIC_IMAGEN_INFO"]
                },
                configSchema: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$imagen$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["ImagenConfigSchema"]
            });
        }),
        // Veo
        ...models.filter((m)=>m.supportedGenerationMethods.includes("predictLongRunning") && m.name.includes("veo")).filter((m)=>!m.description || !m.description.includes("deprecated")).map((m)=>{
            const name = m.name.split("/").at(-1);
            return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$genkit$2f$lib$2f$common$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["modelActionMetadata"])({
                name: `googleai/${name}`,
                info: {
                    ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$veo$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["GENERIC_VEO_INFO"]
                },
                configSchema: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$veo$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["VeoConfigSchema"],
                background: true
            });
        }),
        // Models
        ...models.filter((m)=>m.supportedGenerationMethods.includes("generateContent")).filter((m)=>!m.description || !m.description.includes("deprecated")).map((m)=>{
            const ref = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["gemini"])(m.name.startsWith("models/") ? m.name.substring("models/".length) : m.name);
            return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$genkit$2f$lib$2f$common$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["modelActionMetadata"])({
                name: ref.name,
                info: ref.info,
                configSchema: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["GeminiConfigSchema"]
            });
        }),
        // Embedders
        ...models.filter((m)=>m.supportedGenerationMethods.includes("embedContent")).filter((m)=>!m.description || !m.description.includes("deprecated")).map((m)=>{
            const name = "googleai/" + (m.name.startsWith("models/") ? m.name.substring("models/".length) : m.name);
            return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$genkit$2f$lib$2f$common$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["embedderActionMetadata"])({
                name,
                configSchema: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$embedder$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["GeminiEmbeddingConfigSchema"],
                info: {
                    dimensions: 768,
                    label: `Google Gen AI - ${name}`,
                    supports: {
                        input: [
                            "text"
                        ]
                    }
                }
            });
        })
    ];
}
function googleAIPlugin(options) {
    let listActionsCache;
    return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$genkit$2f$lib$2f$plugin$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["genkitPlugin"])("googleai", async (ai)=>await initializer(ai, options), async (ai, actionType, actionName)=>await resolver(ai, actionType, actionName, options), async ()=>{
        if (listActionsCache) return listActionsCache;
        listActionsCache = await listActions(options);
        return listActionsCache;
    });
}
const googleAI = googleAIPlugin;
googleAI.model = (name, config)=>{
    if (name.startsWith("imagen")) {
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$ai$2f$lib$2f$model$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$locals$3e$__["modelRef"])({
            name: `googleai/${name}`,
            config,
            configSchema: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$imagen$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["ImagenConfigSchema"]
        });
    }
    if (name.startsWith("veo")) {
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$ai$2f$lib$2f$model$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$locals$3e$__["modelRef"])({
            name: `googleai/${name}`,
            config,
            configSchema: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$veo$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["VeoConfigSchema"]
        });
    }
    return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$ai$2f$lib$2f$model$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$locals$3e$__["modelRef"])({
        name: `googleai/${name}`,
        config,
        configSchema: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["GeminiConfigSchema"]
    });
};
googleAI.embedder = (name, config)=>{
    return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$genkit$2f$lib$2f$common$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["embedderRef"])({
        name: `googleai/${name}`,
        config,
        configSchema: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$embedder$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["GeminiEmbeddingConfigSchema"]
    });
};
var index_default = googleAI;
;
 //# sourceMappingURL=index.mjs.map
}}),
"[project]/node_modules/@genkit-ai/googleai/lib/index.mjs [app-rsc] (ecmascript) <module evaluation>": ((__turbopack_context__) => {
"use strict";

var { g: global, __dirname } = __turbopack_context__;
{
__turbopack_context__.s({});
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$genkit$2f$lib$2f$index$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$module__evaluation$3e$__ = __turbopack_context__.i("[project]/node_modules/genkit/lib/index.mjs [app-rsc] (ecmascript) <module evaluation>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$genkit$2f$lib$2f$logging$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$module__evaluation$3e$__ = __turbopack_context__.i("[project]/node_modules/genkit/lib/logging.mjs [app-rsc] (ecmascript) <module evaluation>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$genkit$2f$lib$2f$model$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$module__evaluation$3e$__ = __turbopack_context__.i("[project]/node_modules/genkit/lib/model.mjs [app-rsc] (ecmascript) <module evaluation>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$genkit$2f$lib$2f$plugin$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/genkit/lib/plugin.mjs [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$common$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/googleai/lib/common.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$embedder$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/googleai/lib/embedder.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/googleai/lib/gemini.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$imagen$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/googleai/lib/imagen.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$list$2d$models$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/googleai/lib/list-models.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$veo$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/googleai/lib/veo.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$index$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/googleai/lib/index.mjs [app-rsc] (ecmascript) <locals>");
}}),
"[project]/node_modules/@genkit-ai/googleai/lib/index.mjs [app-rsc] (ecmascript) <exports>": ((__turbopack_context__) => {
"use strict";

var { g: global, __dirname } = __turbopack_context__;
{
__turbopack_context__.s({
    "default": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$index$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$locals$3e$__["default"]),
    "gemini": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["gemini"]),
    "gemini10Pro": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["gemini10Pro"]),
    "gemini15Flash": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["gemini15Flash"]),
    "gemini15Flash8b": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["gemini15Flash8b"]),
    "gemini15Pro": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["gemini15Pro"]),
    "gemini20Flash": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["gemini20Flash"]),
    "gemini20FlashExp": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["gemini20FlashExp"]),
    "gemini20FlashLite": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["gemini20FlashLite"]),
    "gemini20ProExp0205": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["gemini20ProExp0205"]),
    "gemini25FlashPreview0417": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["gemini25FlashPreview0417"]),
    "gemini25ProExp0325": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["gemini25ProExp0325"]),
    "gemini25ProPreview0325": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["gemini25ProPreview0325"]),
    "googleAI": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$index$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$locals$3e$__["googleAI"]),
    "googleAIPlugin": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$index$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$locals$3e$__["googleAIPlugin"]),
    "textEmbedding004": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$embedder$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["textEmbedding004"]),
    "textEmbeddingGecko001": (()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$embedder$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__["textEmbeddingGecko001"])
});
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$embedder$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/googleai/lib/embedder.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$gemini$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/googleai/lib/gemini.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$googleai$2f$lib$2f$index$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/googleai/lib/index.mjs [app-rsc] (ecmascript) <locals>");
}}),
"[project]/node_modules/@genkit-ai/flow/lib/chunk-7OAPEGJQ.mjs [app-rsc] (ecmascript)": ((__turbopack_context__) => {
"use strict";

var { g: global, __dirname } = __turbopack_context__;
{
__turbopack_context__.s({
    "__async": (()=>__async),
    "__asyncGenerator": (()=>__asyncGenerator),
    "__await": (()=>__await),
    "__spreadProps": (()=>__spreadProps),
    "__spreadValues": (()=>__spreadValues)
});
var __defProp = Object.defineProperty;
var __defProps = Object.defineProperties;
var __getOwnPropDescs = Object.getOwnPropertyDescriptors;
var __getOwnPropSymbols = Object.getOwnPropertySymbols;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __propIsEnum = Object.prototype.propertyIsEnumerable;
var __knownSymbol = (name, symbol)=>{
    return (symbol = Symbol[name]) ? symbol : Symbol.for("Symbol." + name);
};
var __defNormalProp = (obj, key, value)=>key in obj ? __defProp(obj, key, {
        enumerable: true,
        configurable: true,
        writable: true,
        value
    }) : obj[key] = value;
var __spreadValues = (a, b)=>{
    for(var prop in b || (b = {}))if (__hasOwnProp.call(b, prop)) __defNormalProp(a, prop, b[prop]);
    if (__getOwnPropSymbols) for (var prop of __getOwnPropSymbols(b)){
        if (__propIsEnum.call(b, prop)) __defNormalProp(a, prop, b[prop]);
    }
    return a;
};
var __spreadProps = (a, b)=>__defProps(a, __getOwnPropDescs(b));
var __async = (__this, __arguments, generator)=>{
    return new Promise((resolve, reject)=>{
        var fulfilled = (value)=>{
            try {
                step(generator.next(value));
            } catch (e) {
                reject(e);
            }
        };
        var rejected = (value)=>{
            try {
                step(generator.throw(value));
            } catch (e) {
                reject(e);
            }
        };
        var step = (x)=>x.done ? resolve(x.value) : Promise.resolve(x.value).then(fulfilled, rejected);
        step((generator = generator.apply(__this, __arguments)).next());
    });
};
var __await = function(promise, isYieldStar) {
    this[0] = promise;
    this[1] = isYieldStar;
};
var __asyncGenerator = (__this, __arguments, generator)=>{
    var resume = (k, v, yes, no)=>{
        try {
            var x = generator[k](v), isAwait = (v = x.value) instanceof __await, done = x.done;
            Promise.resolve(isAwait ? v[0] : v).then((y)=>isAwait ? resume(k === "return" ? k : "next", v[1] ? {
                    done: y.done,
                    value: y.value
                } : y, yes, no) : yes({
                    value: y,
                    done
                })).catch((e)=>resume("throw", e, yes, no));
        } catch (e) {
            no(e);
        }
    };
    var method = (k)=>it[k] = (x)=>new Promise((yes, no)=>resume(k, x, yes, no));
    var it = {};
    return generator = generator.apply(__this, __arguments), it[__knownSymbol("asyncIterator")] = ()=>it, method("next"), method("throw"), method("return"), it;
};
;
 //# sourceMappingURL=chunk-7OAPEGJQ.mjs.map
}}),
"[project]/node_modules/@genkit-ai/flow/lib/firestoreStateStore.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var __async = (__this, __arguments, generator)=>{
    return new Promise((resolve, reject)=>{
        var fulfilled = (value)=>{
            try {
                step(generator.next(value));
            } catch (e) {
                reject(e);
            }
        };
        var rejected = (value)=>{
            try {
                step(generator.throw(value));
            } catch (e) {
                reject(e);
            }
        };
        var step = (x)=>x.done ? resolve(x.value) : Promise.resolve(x.value).then(fulfilled, rejected);
        step((generator = generator.apply(__this, __arguments)).next());
    });
};
var firestoreStateStore_exports = {};
__export(firestoreStateStore_exports, {
    FirestoreStateStore: ()=>FirestoreStateStore
});
module.exports = __toCommonJS(firestoreStateStore_exports);
var import_core = __turbopack_context__.r("[project]/node_modules/@genkit-ai/flow/node_modules/@genkit-ai/core/lib/index.js [app-rsc] (ecmascript)");
var import_logging = __turbopack_context__.r("[project]/node_modules/@genkit-ai/flow/node_modules/@genkit-ai/core/lib/logging.js [app-rsc] (ecmascript)");
var import_firestore = __turbopack_context__.r("[project]/node_modules/@google-cloud/firestore/build/src/index.js [app-rsc] (ecmascript)");
class FirestoreStateStore {
    constructor(params = {}){
        this.collection = params.collection || "genkit-flows";
        this.databaseId = params.databaseId || "(default)";
        this.db = new import_firestore.Firestore({
            databaseId: this.databaseId,
            ignoreUndefinedProperties: true,
            credentials: params.credentials
        });
    }
    load(id) {
        return __async(this, null, function*() {
            const data = (yield this.db.collection(this.collection).doc(id).get()).data();
            if (!data) {
                return void 0;
            }
            return import_core.FlowStateSchema.parse(data);
        });
    }
    save(id, state) {
        return __async(this, null, function*() {
            import_logging.logger.debug(state, "save state");
            yield this.db.collection(this.collection).doc(id).set(state);
        });
    }
    list(query) {
        return __async(this, null, function*() {
            const limit = (query == null ? void 0 : query.limit) || 10;
            let fsQuery = this.db.collection(this.collection).orderBy("startTime", "desc");
            if (query == null ? void 0 : query.continuationToken) {
                fsQuery = fsQuery.startAfter(parseInt(query.continuationToken));
            }
            fsQuery = fsQuery.limit(limit);
            const data = yield fsQuery.get();
            const lastVisible = data.docs[data.docs.length - 1];
            return {
                flowStates: data.docs.map((d)=>d.data()),
                continuationToken: data.docs.length === limit ? `${lastVisible.data().startTime}` : void 0
            };
        });
    }
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    FirestoreStateStore
}); //# sourceMappingURL=firestoreStateStore.js.map
}}),
"[project]/node_modules/@genkit-ai/flow/lib/errors.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var errors_exports = {};
__export(errors_exports, {
    FlowExecutionError: ()=>FlowExecutionError,
    FlowNotFoundError: ()=>FlowNotFoundError,
    FlowStillRunningError: ()=>FlowStillRunningError,
    InterruptError: ()=>InterruptError,
    getErrorMessage: ()=>getErrorMessage,
    getErrorStack: ()=>getErrorStack
});
module.exports = __toCommonJS(errors_exports);
class InterruptError extends Error {
}
function getErrorMessage(e) {
    if (e instanceof Error) {
        return e.message;
    }
    return `${e}`;
}
function getErrorStack(e) {
    if (e instanceof Error) {
        return e.stack;
    }
    return void 0;
}
class FlowNotFoundError extends Error {
    constructor(msg){
        super(msg);
    }
}
class FlowStillRunningError extends Error {
    constructor(flowId){
        super(`flow ${flowId} is not done execution. Consider using waitForFlowToComplete to wait for completion before calling getOutput.`);
        this.flowId = flowId;
    }
}
class FlowExecutionError extends Error {
    constructor(flowId, originalMessage, originalStacktrace){
        super(originalMessage);
        this.flowId = flowId;
        this.originalMessage = originalMessage;
        this.originalStacktrace = originalStacktrace;
        this.stack = originalStacktrace;
    }
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    FlowExecutionError,
    FlowNotFoundError,
    FlowStillRunningError,
    InterruptError,
    getErrorMessage,
    getErrorStack
}); //# sourceMappingURL=errors.js.map
}}),
"[project]/node_modules/@genkit-ai/flow/lib/utils.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var utils_exports = {};
__export(utils_exports, {
    generateFlowId: ()=>generateFlowId,
    getActiveContext: ()=>getActiveContext,
    getFlowAuth: ()=>getFlowAuth,
    metadataPrefix: ()=>metadataPrefix,
    runWithActiveContext: ()=>runWithActiveContext
});
module.exports = __toCommonJS(utils_exports);
var import_node_async_hooks = __turbopack_context__.r("[externals]/node:async_hooks [external] (node:async_hooks, cjs)");
var import_uuid = __turbopack_context__.r("[project]/node_modules/@genkit-ai/flow/node_modules/uuid/dist/esm-node/index.js [app-rsc] (ecmascript)");
function metadataPrefix(name) {
    return `flow:${name}`;
}
const ctxAsyncLocalStorage = new import_node_async_hooks.AsyncLocalStorage();
function getActiveContext() {
    return ctxAsyncLocalStorage.getStore();
}
function runWithActiveContext(ctx, fn) {
    return ctxAsyncLocalStorage.run(ctx, fn);
}
function generateFlowId() {
    return (0, import_uuid.v4)();
}
function getFlowAuth() {
    const ctx = getActiveContext();
    if (!ctx) {
        throw new Error("Can only be run from a flow");
    }
    return ctx.auth;
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    generateFlowId,
    getActiveContext,
    getFlowAuth,
    metadataPrefix,
    runWithActiveContext
}); //# sourceMappingURL=utils.js.map
}}),
"[project]/node_modules/@genkit-ai/flow/lib/context.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var __async = (__this, __arguments, generator)=>{
    return new Promise((resolve, reject)=>{
        var fulfilled = (value)=>{
            try {
                step(generator.next(value));
            } catch (e) {
                reject(e);
            }
        };
        var rejected = (value)=>{
            try {
                step(generator.throw(value));
            } catch (e) {
                reject(e);
            }
        };
        var step = (x)=>x.done ? resolve(x.value) : Promise.resolve(x.value).then(fulfilled, rejected);
        step((generator = generator.apply(__this, __arguments)).next());
    });
};
var context_exports = {};
__export(context_exports, {
    Context: ()=>Context
});
module.exports = __toCommonJS(context_exports);
var import_schema = __turbopack_context__.r("[project]/node_modules/@genkit-ai/flow/node_modules/@genkit-ai/core/lib/schema.js [app-rsc] (ecmascript)");
var import_tracing = __turbopack_context__.r("[project]/node_modules/@genkit-ai/flow/node_modules/@genkit-ai/core/lib/tracing.js [app-rsc] (ecmascript)");
var import_v1 = __turbopack_context__.r("[project]/node_modules/firebase-functions/lib/v1/index.js [app-rsc] (ecmascript)");
var import_errors = __turbopack_context__.r("[project]/node_modules/@genkit-ai/flow/lib/errors.js [app-rsc] (ecmascript)");
var import_utils = __turbopack_context__.r("[project]/node_modules/@genkit-ai/flow/lib/utils.js [app-rsc] (ecmascript)");
class Context {
    constructor(flow, flowId, state, auth){
        this.flow = flow;
        this.flowId = flowId;
        this.state = state;
        this.auth = auth;
        this.seenSteps = {};
    }
    isCached(stepName) {
        return this.state.cache.hasOwnProperty(stepName);
    }
    getCached(stepName) {
        return this.state.cache[stepName].value;
    }
    updateCachedValue(stepName, value) {
        this.state.cache[stepName] = value ? {
            value
        } : {
            empty: true
        };
    }
    memoize(stepName, func) {
        return __async(this, null, function*() {
            if (this.isCached(stepName)) {
                return [
                    this.getCached(stepName),
                    true
                ];
            }
            const value = yield func();
            this.updateCachedValue(stepName, value);
            return [
                value,
                false
            ];
        });
    }
    saveState() {
        return __async(this, null, function*() {
            if (this.flow.stateStore) {
                yield (yield this.flow.stateStore()).save(this.flowId, this.state);
            }
        });
    }
    // Runs provided function in the current context. The config can specify retry and other behaviors.
    run(config, input, func) {
        return __async(this, null, function*() {
            return yield (0, import_tracing.runInNewSpan)({
                metadata: {
                    name: config.name
                },
                labels: {
                    [import_tracing.SPAN_TYPE_ATTR]: "flowStep"
                }
            }, (metadata, _, isRoot)=>__async(this, null, function*() {
                    const stepName = this.resolveStepName(config.name);
                    (0, import_tracing.setCustomMetadataAttributes)({
                        [(0, import_utils.metadataPrefix)("stepType")]: "run",
                        [(0, import_utils.metadataPrefix)("stepName")]: config.name,
                        [(0, import_utils.metadataPrefix)("resolvedStepName")]: stepName
                    });
                    if (input !== void 0) {
                        metadata.input = input;
                    }
                    const [value, wasCached] = isRoot ? yield this.memoize(stepName, func) : [
                        (yield func()),
                        false
                    ];
                    if (wasCached) {
                        (0, import_tracing.setCustomMetadataAttribute)((0, import_utils.metadataPrefix)("state"), "cached");
                    } else {
                        (0, import_tracing.setCustomMetadataAttribute)((0, import_utils.metadataPrefix)("state"), "run");
                        if (value !== void 0) {
                            metadata.output = JSON.stringify(value);
                        }
                    }
                    return value;
                }));
        });
    }
    resolveStepName(name) {
        if (this.seenSteps[name] !== void 0) {
            this.seenSteps[name]++;
            name += `-${this.seenSteps[name]}`;
        } else {
            this.seenSteps[name] = 0;
        }
        return name;
    }
    // Executes interrupt step in the current context.
    interrupt(stepName, func, responseSchema, skipCache) {
        return __async(this, null, function*() {
            return yield (0, import_tracing.runInNewSpan)({
                metadata: {
                    name: stepName
                },
                labels: {
                    [import_tracing.SPAN_TYPE_ATTR]: "flowStep"
                }
            }, (metadata)=>__async(this, null, function*() {
                    const resolvedStepName = this.resolveStepName(stepName);
                    (0, import_tracing.setCustomMetadataAttributes)({
                        [(0, import_utils.metadataPrefix)("stepType")]: "interrupt",
                        [(0, import_utils.metadataPrefix)("stepName")]: stepName,
                        [(0, import_utils.metadataPrefix)("resolvedStepName")]: resolvedStepName
                    });
                    if (!skipCache && this.isCached(resolvedStepName)) {
                        (0, import_tracing.setCustomMetadataAttribute)((0, import_utils.metadataPrefix)("state"), "skipped");
                        return this.getCached(resolvedStepName);
                    }
                    if (this.state.eventsTriggered.hasOwnProperty(resolvedStepName)) {
                        let value;
                        try {
                            value = yield func(this.state.eventsTriggered[resolvedStepName]);
                        } catch (e) {
                            if (e instanceof import_errors.InterruptError) {
                                (0, import_tracing.setCustomMetadataAttribute)((0, import_utils.metadataPrefix)("state"), "interrupt");
                            } else {
                                (0, import_tracing.setCustomMetadataAttribute)((0, import_utils.metadataPrefix)("state"), "error");
                            }
                            throw e;
                        }
                        this.state.blockedOnStep = null;
                        if (!skipCache) {
                            this.updateCachedValue(resolvedStepName, value);
                        }
                        (0, import_tracing.setCustomMetadataAttribute)((0, import_utils.metadataPrefix)("state"), "dispatch");
                        if (value !== void 0) {
                            metadata.output = JSON.stringify(value);
                        }
                        return value;
                    }
                    import_v1.logger.debug("blockedOnStep", resolvedStepName);
                    this.state.blockedOnStep = {
                        name: resolvedStepName
                    };
                    if (responseSchema) {
                        this.state.blockedOnStep.schema = JSON.stringify((0, import_schema.toJsonSchema)({
                            schema: responseSchema
                        }));
                    }
                    (0, import_tracing.setCustomMetadataAttribute)((0, import_utils.metadataPrefix)("state"), "interrupted");
                    throw new import_errors.InterruptError();
                }));
        });
    }
    // Sleep for the specified number of seconds.
    sleep(stepName, seconds) {
        return __async(this, null, function*() {
            const resolvedStepName = this.resolveStepName(stepName);
            if (this.isCached(resolvedStepName)) {
                (0, import_tracing.setCustomMetadataAttribute)((0, import_utils.metadataPrefix)("state"), "skipped");
                return this.getCached(resolvedStepName);
            }
            yield this.flow.scheduler(this.flow, {
                runScheduled: {
                    flowId: this.flowId
                }
            }, seconds);
            this.updateCachedValue(resolvedStepName, void 0);
            return this.interrupt(stepName, (input)=>input, null);
        });
    }
    /**
   * Wait for the provided flow to complete execution. This will do a poll.
   * Poll will be done with an exponential backoff (configurable).
   */ waitFor(opts) {
        return __async(this, null, function*() {
            var _a;
            const resolvedStepName = this.resolveStepName(opts.stepName);
            if (this.isCached(resolvedStepName)) {
                return this.getCached(resolvedStepName);
            }
            const states = yield this.getFlowsOperations(opts.flow, opts.flowIds);
            if (states.includes(void 0)) {
                throw new Error("Unable to resolve flow state for " + opts.flowIds[states.indexOf(void 0)]);
            }
            const ops = states.map((s)=>s.operation);
            if (ops.map((op)=>op.done).reduce((a, b)=>a && b)) {
                this.updateCachedValue(resolvedStepName, states);
                return ops;
            }
            yield this.flow.scheduler(this.flow, {
                runScheduled: {
                    flowId: this.flowId
                }
            }, ((_a = opts.pollingConfig) == null ? void 0 : _a.interval) || 5);
            throw new import_errors.InterruptError();
        });
    }
    getFlowsOperations(flow, flowIds) {
        return __async(this, null, function*() {
            return yield Promise.all(flowIds.map((id)=>__async(this, null, function*() {
                    if (!flow.stateStore) {
                        throw new Error("Flow state store must be configured");
                    }
                    return (yield flow.stateStore()).load(id);
                })));
        });
    }
    /**
   * Returns current active execution state.
   */ getCurrentExecution() {
        return this.state.executions[this.state.executions.length - 1];
    }
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    Context
}); //# sourceMappingURL=context.js.map
}}),
"[project]/node_modules/@genkit-ai/flow/lib/types.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var types_exports = {};
__export(types_exports, {
    FlowActionInputSchema: ()=>FlowActionInputSchema,
    FlowInvokeEnvelopeMessageSchema: ()=>FlowInvokeEnvelopeMessageSchema
});
module.exports = __toCommonJS(types_exports);
var import_zod = __turbopack_context__.r("[project]/node_modules/zod/lib/index.js [app-rsc] (ecmascript)");
const FlowInvokeEnvelopeMessageSchema = import_zod.z.object({
    // Start new flow.
    start: import_zod.z.object({
        input: import_zod.z.unknown().optional(),
        labels: import_zod.z.record(import_zod.z.string(), import_zod.z.string()).optional()
    }).optional(),
    // Schedule new flow.
    schedule: import_zod.z.object({
        input: import_zod.z.unknown().optional(),
        delay: import_zod.z.number().optional()
    }).optional(),
    // Run previously scheduled flow.
    runScheduled: import_zod.z.object({
        flowId: import_zod.z.string()
    }).optional(),
    // Retry failed step (only if step is setup for retry)
    retry: import_zod.z.object({
        flowId: import_zod.z.string()
    }).optional(),
    // Resume an interrupted flow.
    resume: import_zod.z.object({
        flowId: import_zod.z.string(),
        payload: import_zod.z.unknown().optional()
    }).optional(),
    // State check for a given flow ID. No side effects, can be used to check flow state.
    state: import_zod.z.object({
        flowId: import_zod.z.string()
    }).optional()
});
const FlowActionInputSchema = FlowInvokeEnvelopeMessageSchema.extend({
    auth: import_zod.z.unknown().optional()
});
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    FlowActionInputSchema,
    FlowInvokeEnvelopeMessageSchema
}); //# sourceMappingURL=types.js.map
}}),
"[project]/node_modules/@genkit-ai/flow/lib/flow.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __knownSymbol = (name, symbol)=>{
    return (symbol = Symbol[name]) ? symbol : Symbol.for("Symbol." + name);
};
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toESM = (mod, isNodeMode, target)=>(target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(// If the importer is in node compatibility mode or this is not an ESM
    // file that has been converted to a CommonJS file using a Babel-
    // compatible transform (i.e. "__esModule" has not been set), then set
    // "default" to the CommonJS "module.exports" for node compatibility.
    isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", {
        value: mod,
        enumerable: true
    }) : target, mod));
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var __async = (__this, __arguments, generator)=>{
    return new Promise((resolve, reject)=>{
        var fulfilled = (value)=>{
            try {
                step(generator.next(value));
            } catch (e) {
                reject(e);
            }
        };
        var rejected = (value)=>{
            try {
                step(generator.throw(value));
            } catch (e) {
                reject(e);
            }
        };
        var step = (x)=>x.done ? resolve(x.value) : Promise.resolve(x.value).then(fulfilled, rejected);
        step((generator = generator.apply(__this, __arguments)).next());
    });
};
var __await = function(promise, isYieldStar) {
    this[0] = promise;
    this[1] = isYieldStar;
};
var __asyncGenerator = (__this, __arguments, generator)=>{
    var resume = (k, v, yes, no)=>{
        try {
            var x = generator[k](v), isAwait = (v = x.value) instanceof __await, done = x.done;
            Promise.resolve(isAwait ? v[0] : v).then((y)=>isAwait ? resume(k === "return" ? k : "next", v[1] ? {
                    done: y.done,
                    value: y.value
                } : y, yes, no) : yes({
                    value: y,
                    done
                })).catch((e)=>resume("throw", e, yes, no));
        } catch (e) {
            no(e);
        }
    };
    var method = (k)=>it[k] = (x)=>new Promise((yes, no)=>resume(k, x, yes, no));
    var it = {};
    return generator = generator.apply(__this, __arguments), it[__knownSymbol("asyncIterator")] = ()=>it, method("next"), method("throw"), method("return"), it;
};
var flow_exports = {};
__export(flow_exports, {
    Flow: ()=>Flow,
    defineFlow: ()=>defineFlow,
    runFlow: ()=>runFlow,
    startFlowsServer: ()=>startFlowsServer,
    streamFlow: ()=>streamFlow
});
module.exports = __toCommonJS(flow_exports);
var import_core = __turbopack_context__.r("[project]/node_modules/@genkit-ai/flow/node_modules/@genkit-ai/core/lib/index.js [app-rsc] (ecmascript)");
var import_logging = __turbopack_context__.r("[project]/node_modules/@genkit-ai/flow/node_modules/@genkit-ai/core/lib/logging.js [app-rsc] (ecmascript)");
var import_schema = __turbopack_context__.r("[project]/node_modules/@genkit-ai/flow/node_modules/@genkit-ai/core/lib/schema.js [app-rsc] (ecmascript)");
var import_tracing = __turbopack_context__.r("[project]/node_modules/@genkit-ai/flow/node_modules/@genkit-ai/core/lib/tracing.js [app-rsc] (ecmascript)");
var import_api = __turbopack_context__.r("[externals]/@opentelemetry/api [external] (@opentelemetry/api, cjs)");
var bodyParser = __toESM(__turbopack_context__.r("[project]/node_modules/body-parser/index.js [app-rsc] (ecmascript)"));
var import_cors = __toESM(__turbopack_context__.r("[project]/node_modules/cors/lib/index.js [app-rsc] (ecmascript)"));
var import_express = __toESM(__turbopack_context__.r("[externals]/express [external] (express, cjs)"));
var import_node_perf_hooks = __turbopack_context__.r("[externals]/node:perf_hooks [external] (node:perf_hooks, cjs)");
var import_context = __turbopack_context__.r("[project]/node_modules/@genkit-ai/flow/lib/context.js [app-rsc] (ecmascript)");
var import_errors = __turbopack_context__.r("[project]/node_modules/@genkit-ai/flow/lib/errors.js [app-rsc] (ecmascript)");
var import_types = __turbopack_context__.r("[project]/node_modules/@genkit-ai/flow/lib/types.js [app-rsc] (ecmascript)");
var import_utils = __turbopack_context__.r("[project]/node_modules/@genkit-ai/flow/lib/utils.js [app-rsc] (ecmascript)");
const streamDelimiter = "\n";
const CREATED_FLOWS = "genkit__CREATED_FLOWS";
function createdFlows() {
    if (global[CREATED_FLOWS] === void 0) {
        global[CREATED_FLOWS] = [];
    }
    return global[CREATED_FLOWS];
}
function defineFlow(config, steps) {
    const f = new Flow({
        name: config.name,
        inputSchema: config.inputSchema,
        outputSchema: config.outputSchema,
        streamSchema: config.streamSchema,
        experimentalDurable: !!config.experimentalDurable,
        stateStore: import_core.config ? ()=>import_core.config.getFlowStateStore() : void 0,
        authPolicy: config.authPolicy,
        middleware: config.middleware,
        // We always use local dispatcher in dev mode or when one is not provided.
        invoker: (flow, msg, streamingCallback)=>__async(this, null, function*() {
                if (!(0, import_core.isDevEnv)() && config.invoker) {
                    return config.invoker(flow, msg, streamingCallback);
                }
                const state = yield flow.runEnvelope(msg, streamingCallback);
                return state.operation;
            }),
        scheduler: (flow, msg, delay = 0)=>__async(this, null, function*() {
                if (!config.experimentalDurable) {
                    throw new Error("This flow is not durable, cannot use scheduling features.");
                }
                if (!(0, import_core.isDevEnv)() && config.experimentalScheduler) {
                    return config.experimentalScheduler(flow, msg, delay);
                }
                setTimeout(()=>flow.runEnvelope(msg), delay * 1e3);
            })
    }, steps);
    createdFlows().push(f);
    wrapAsAction(f);
    return f;
}
class Flow {
    constructor(config, steps){
        this.steps = steps;
        this.name = config.name;
        this.inputSchema = config.inputSchema;
        this.outputSchema = config.outputSchema;
        this.streamSchema = config.streamSchema;
        this.stateStore = config.stateStore;
        this.invoker = config.invoker;
        this.scheduler = config.scheduler;
        this.experimentalDurable = config.experimentalDurable;
        this.authPolicy = config.authPolicy;
        this.middleware = config.middleware;
        if (this.authPolicy && this.experimentalDurable) {
            throw new Error("Durable flows can not define auth policies.");
        }
    }
    /**
   * Executes the flow with the input directly.
   *
   * This will either be called by runEnvelope when starting durable flows,
   * or it will be called directly when starting non-durable flows.
   */ runDirectly(input, opts) {
        return __async(this, null, function*() {
            const flowId = (0, import_utils.generateFlowId)();
            const state = createNewState(flowId, this.name, input);
            const ctx = new import_context.Context(this, flowId, state, opts.auth);
            try {
                yield this.executeSteps(ctx, this.steps, "start", opts.streamingCallback, opts.labels);
            } finally{
                if ((0, import_core.isDevEnv)() || this.experimentalDurable) {
                    yield ctx.saveState();
                }
            }
            return state;
        });
    }
    /**
   * Executes the flow with the input in the envelope format.
   */ runEnvelope(req, streamingCallback, auth) {
        return __async(this, null, function*() {
            import_logging.logger.debug(req, "runEnvelope");
            if (req.start) {
                return this.runDirectly(req.start.input, {
                    streamingCallback,
                    auth,
                    labels: req.start.labels
                });
            }
            if (req.schedule) {
                if (!this.experimentalDurable) {
                    throw new Error("Cannot schedule a non-durable flow");
                }
                if (!this.stateStore) {
                    throw new Error("Flow state store for durable flows must be configured");
                }
                const flowId = (0, import_utils.generateFlowId)();
                const state = createNewState(flowId, this.name, req.schedule.input);
                try {
                    yield (yield this.stateStore()).save(flowId, state);
                    yield this.scheduler(this, {
                        runScheduled: {
                            flowId
                        }
                    }, req.schedule.delay);
                } catch (e) {
                    state.operation.done = true;
                    state.operation.result = {
                        error: (0, import_errors.getErrorMessage)(e),
                        stacktrace: (0, import_errors.getErrorStack)(e)
                    };
                    yield (yield this.stateStore()).save(flowId, state);
                }
                return state;
            }
            if (req.state) {
                if (!this.experimentalDurable) {
                    throw new Error("Cannot state check a non-durable flow");
                }
                if (!this.stateStore) {
                    throw new Error("Flow state store for durable flows must be configured");
                }
                const flowId = req.state.flowId;
                const state = yield (yield this.stateStore()).load(flowId);
                if (state === void 0) {
                    throw new Error(`Unable to find flow state for ${flowId}`);
                }
                return state;
            }
            if (req.runScheduled) {
                if (!this.experimentalDurable) {
                    throw new Error("Cannot run scheduled non-durable flow");
                }
                if (!this.stateStore) {
                    throw new Error("Flow state store for durable flows must be configured");
                }
                const flowId = req.runScheduled.flowId;
                const state = yield (yield this.stateStore()).load(flowId);
                if (state === void 0) {
                    throw new Error(`Unable to find flow state for ${flowId}`);
                }
                const ctx = new import_context.Context(this, flowId, state);
                try {
                    yield this.executeSteps(ctx, this.steps, "runScheduled", void 0, void 0);
                } finally{
                    yield ctx.saveState();
                }
                return state;
            }
            if (req.resume) {
                if (!this.experimentalDurable) {
                    throw new Error("Cannot resume a non-durable flow");
                }
                if (!this.stateStore) {
                    throw new Error("Flow state store for durable flows must be configured");
                }
                const flowId = req.resume.flowId;
                const state = yield (yield this.stateStore()).load(flowId);
                if (state === void 0) {
                    throw new Error(`Unable to find flow state for ${flowId}`);
                }
                if (!state.blockedOnStep) {
                    throw new Error("Unable to resume flow that's currently not interrupted");
                }
                state.eventsTriggered[state.blockedOnStep.name] = req.resume.payload;
                const ctx = new import_context.Context(this, flowId, state);
                try {
                    yield this.executeSteps(ctx, this.steps, "resume", void 0, void 0);
                } finally{
                    yield ctx.saveState();
                }
                return state;
            }
            throw new Error("Unexpected envelope message case, must set one of: start, schedule, runScheduled, resume, retry, state");
        });
    }
    // TODO: refactor me... this is a mess!
    executeSteps(ctx, handler, dispatchType, streamingCallback, labels) {
        return __async(this, null, function*() {
            const startTimeMs = import_node_perf_hooks.performance.now();
            yield (0, import_utils.runWithActiveContext)(ctx, ()=>__async(this, null, function*() {
                    let traceContext;
                    if (ctx.state.traceContext) {
                        traceContext = JSON.parse(ctx.state.traceContext);
                    }
                    let ctxLinks = traceContext ? [
                        {
                            context: traceContext
                        }
                    ] : [];
                    let errored = false;
                    const output = yield (0, import_tracing.newTrace)({
                        name: ctx.flow.name,
                        labels: {
                            [import_tracing.SPAN_TYPE_ATTR]: "flow"
                        },
                        links: ctxLinks
                    }, (metadata, rootSpan)=>__async(this, null, function*() {
                            ctx.state.executions.push({
                                startTime: Date.now(),
                                traceIds: []
                            });
                            (0, import_tracing.setCustomMetadataAttribute)((0, import_utils.metadataPrefix)(`execution`), (ctx.state.executions.length - 1).toString());
                            if (labels) {
                                Object.keys(labels).forEach((label)=>{
                                    (0, import_tracing.setCustomMetadataAttribute)((0, import_utils.metadataPrefix)(`label:${label}`), labels[label]);
                                });
                            }
                            (0, import_tracing.setCustomMetadataAttributes)({
                                [(0, import_utils.metadataPrefix)("name")]: this.name,
                                [(0, import_utils.metadataPrefix)("id")]: ctx.flowId
                            });
                            ctx.getCurrentExecution().traceIds.push(rootSpan.spanContext().traceId);
                            if (!traceContext) {
                                ctx.state.traceContext = JSON.stringify(rootSpan.spanContext());
                            }
                            (0, import_tracing.setCustomMetadataAttribute)((0, import_utils.metadataPrefix)("dispatchType"), dispatchType);
                            try {
                                const input = this.inputSchema ? this.inputSchema.parse(ctx.state.input) : ctx.state.input;
                                metadata.input = input;
                                const output2 = yield handler(input, streamingCallback);
                                metadata.output = JSON.stringify(output2);
                                (0, import_tracing.setCustomMetadataAttribute)((0, import_utils.metadataPrefix)("state"), "done");
                                return output2;
                            } catch (e) {
                                if (e instanceof import_errors.InterruptError) {
                                    (0, import_tracing.setCustomMetadataAttribute)((0, import_utils.metadataPrefix)("state"), "interrupted");
                                } else {
                                    metadata.state = "error";
                                    rootSpan.setStatus({
                                        code: import_api.SpanStatusCode.ERROR,
                                        message: (0, import_errors.getErrorMessage)(e)
                                    });
                                    if (e instanceof Error) {
                                        rootSpan.recordException(e);
                                    }
                                    (0, import_tracing.setCustomMetadataAttribute)((0, import_utils.metadataPrefix)("state"), "error");
                                    ctx.state.operation.done = true;
                                    ctx.state.operation.result = {
                                        error: (0, import_errors.getErrorMessage)(e),
                                        stacktrace: (0, import_errors.getErrorStack)(e)
                                    };
                                }
                                errored = true;
                            }
                        }));
                    if (!errored) {
                        ctx.state.operation.done = true;
                        ctx.state.operation.result = {
                            response: output
                        };
                    }
                }));
        });
    }
    durableExpressHandler(req, res) {
        return __async(this, null, function*() {
            if (req.query.stream === "true") {
                const respBody = {
                    error: {
                        status: "INVALID_ARGUMENT",
                        message: "Output from durable flows cannot be streamed"
                    }
                };
                res.status(400).send(respBody).end();
                return;
            }
            let data = req.body;
            if (req.body.data) {
                data = req.body.data;
            }
            const envMsg = import_types.FlowInvokeEnvelopeMessageSchema.parse(data);
            try {
                const state = yield this.runEnvelope(envMsg);
                res.status(200).send(state.operation).end();
            } catch (e) {
                const respBody = {
                    done: true,
                    result: {
                        error: (0, import_errors.getErrorMessage)(e),
                        stacktrace: (0, import_errors.getErrorStack)(e)
                    }
                };
                res.status(500).send(respBody).end();
            }
        });
    }
    nonDurableExpressHandler(req, res) {
        return __async(this, null, function*() {
            var _a, _b, _c, _d;
            const { stream } = req.query;
            const auth = req.auth;
            let input = req.body.data;
            try {
                yield (_a = this.authPolicy) == null ? void 0 : _a.call(this, auth, input);
            } catch (e) {
                const respBody = {
                    error: {
                        status: "PERMISSION_DENIED",
                        message: e.message || "Permission denied to resource"
                    }
                };
                res.status(403).send(respBody).end();
                return;
            }
            if (stream === "true") {
                res.writeHead(200, {
                    "Content-Type": "text/plain",
                    "Transfer-Encoding": "chunked"
                });
                try {
                    const state = yield this.runDirectly(input, {
                        streamingCallback: (chunk)=>{
                            res.write(JSON.stringify(chunk) + streamDelimiter);
                        },
                        auth
                    });
                    res.write(JSON.stringify(state.operation));
                    res.end();
                } catch (e) {
                    const respBody = {
                        done: true,
                        result: {
                            error: (0, import_errors.getErrorMessage)(e),
                            stacktrace: (0, import_errors.getErrorStack)(e)
                        }
                    };
                    res.write(JSON.stringify(respBody));
                    res.end();
                }
            } else {
                try {
                    const state = yield this.runDirectly(input, {
                        auth
                    });
                    if ((_b = state.operation.result) == null ? void 0 : _b.error) {
                        throw new Error((_c = state.operation.result) == null ? void 0 : _c.error);
                    }
                    res.status(200).send({
                        result: (_d = state.operation.result) == null ? void 0 : _d.response
                    }).end();
                } catch (e) {
                    res.status(500).send({
                        error: {
                            status: "INTERNAL",
                            message: (0, import_errors.getErrorMessage)(e),
                            details: (0, import_errors.getErrorStack)(e)
                        }
                    }).end();
                }
            }
        });
    }
    get expressHandler() {
        return this.experimentalDurable ? this.durableExpressHandler.bind(this) : this.nonDurableExpressHandler.bind(this);
    }
}
function runFlow(flow, payload, opts) {
    return __async(this, null, function*() {
        var _a, _b, _c, _d, _e;
        if (!(flow instanceof Flow)) {
            flow = flow.flow;
        }
        const input = flow.inputSchema ? flow.inputSchema.parse(payload) : payload;
        yield (_a = flow.authPolicy) == null ? void 0 : _a.call(flow, opts == null ? void 0 : opts.withLocalAuthContext, payload);
        if (flow.middleware) {
            import_logging.logger.warn(`Flow (${flow.name}) middleware won't run when invoked with runFlow.`);
        }
        const state = yield flow.runEnvelope({
            start: {
                input
            }
        }, void 0, opts == null ? void 0 : opts.withLocalAuthContext);
        if (!state.operation.done) {
            throw new import_errors.FlowStillRunningError(`flow ${state.name} did not finish execution`);
        }
        if ((_b = state.operation.result) == null ? void 0 : _b.error) {
            throw new import_errors.FlowExecutionError(state.operation.name, (_c = state.operation.result) == null ? void 0 : _c.error, (_d = state.operation.result) == null ? void 0 : _d.stacktrace);
        }
        return (_e = state.operation.result) == null ? void 0 : _e.response;
    });
}
function streamFlow(flowOrFlowWrapper, payload, opts) {
    var _a, _b;
    const flow = !(flowOrFlowWrapper instanceof Flow) ? flowOrFlowWrapper.flow : flowOrFlowWrapper;
    let chunkStreamController;
    const chunkStream = new ReadableStream({
        start (controller) {
            chunkStreamController = controller;
        },
        pull () {},
        cancel () {}
    });
    const authPromise = (_b = (_a = flow.authPolicy) == null ? void 0 : _a.call(flow, opts == null ? void 0 : opts.withLocalAuthContext, payload)) != null ? _b : Promise.resolve();
    const operationPromise = authPromise.then(()=>flow.runEnvelope({
            start: {
                input: flow.inputSchema ? flow.inputSchema.parse(payload) : payload
            }
        }, (c)=>{
            chunkStreamController.enqueue(c);
        }, opts == null ? void 0 : opts.withLocalAuthContext)).then((s)=>s.operation).finally(()=>{
        chunkStreamController.close();
    });
    return {
        output () {
            return operationPromise.then((op)=>{
                var _a2, _b2, _c2, _d;
                if (!op.done) {
                    throw new import_errors.FlowStillRunningError(`flow ${op.name} did not finish execution`);
                }
                if ((_a2 = op.result) == null ? void 0 : _a2.error) {
                    throw new import_errors.FlowExecutionError(op.name, (_b2 = op.result) == null ? void 0 : _b2.error, (_c2 = op.result) == null ? void 0 : _c2.stacktrace);
                }
                return (_d = op.result) == null ? void 0 : _d.response;
            });
        },
        stream () {
            return __asyncGenerator(this, null, function*() {
                const reader = chunkStream.getReader();
                while(true){
                    const chunk = yield new __await(reader.read());
                    if (chunk.value) {
                        yield chunk.value;
                    }
                    if (chunk.done) {
                        break;
                    }
                }
                return yield new __await(operationPromise);
            });
        }
    };
}
function createNewState(flowId, name, input) {
    return {
        flowId,
        name,
        startTime: Date.now(),
        input,
        cache: {},
        eventsTriggered: {},
        blockedOnStep: null,
        executions: [],
        operation: {
            name: flowId,
            done: false
        }
    };
}
function wrapAsAction(flow) {
    return (0, import_core.defineAction)({
        actionType: "flow",
        name: flow.name,
        inputSchema: import_types.FlowActionInputSchema,
        outputSchema: import_core.FlowStateSchema,
        metadata: {
            inputSchema: (0, import_schema.toJsonSchema)({
                schema: flow.inputSchema
            }),
            outputSchema: (0, import_schema.toJsonSchema)({
                schema: flow.outputSchema
            }),
            experimentalDurable: !!flow.experimentalDurable,
            requiresAuth: !!flow.authPolicy
        }
    }, (envelope)=>__async(this, null, function*() {
            var _a, _b;
            yield (_b = flow.authPolicy) == null ? void 0 : _b.call(flow, envelope.auth, (_a = envelope.start) == null ? void 0 : _a.input);
            (0, import_tracing.setCustomMetadataAttribute)((0, import_utils.metadataPrefix)("wrapperAction"), "true");
            return yield flow.runEnvelope(envelope, (0, import_core.getStreamingCallback)(), envelope.auth);
        }));
}
function startFlowsServer(params) {
    var _a;
    const port = (params == null ? void 0 : params.port) || (process.env.PORT ? parseInt(process.env.PORT) : 0) || 3400;
    const pathPrefix = (_a = params == null ? void 0 : params.pathPrefix) != null ? _a : "";
    const app = (0, import_express.default)();
    app.use(bodyParser.json(params == null ? void 0 : params.jsonParserOptions));
    app.use((0, import_cors.default)(params == null ? void 0 : params.cors));
    const flows = (params == null ? void 0 : params.flows) || createdFlows();
    import_logging.logger.info(`Starting flows server on port ${port}`);
    flows.forEach((f)=>{
        var _a2;
        const flowPath = `/${pathPrefix}${f.name}`;
        import_logging.logger.info(` - ${flowPath}`);
        (_a2 = f.middleware) == null ? void 0 : _a2.forEach((m)=>{
            app.post(flowPath, m);
        });
        app.post(flowPath, f.expressHandler);
    });
    app.listen(port, ()=>{
        console.log(`Flows server listening on port ${port}`);
    });
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    Flow,
    defineFlow,
    runFlow,
    startFlowsServer,
    streamFlow
}); //# sourceMappingURL=flow.js.map
}}),
"[project]/node_modules/@genkit-ai/flow/lib/steps.js [app-rsc] (ecmascript)": (function(__turbopack_context__) {

var { g: global, __dirname, m: module, e: exports } = __turbopack_context__;
{
"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all)=>{
    for(var name in all)__defProp(target, name, {
        get: all[name],
        enumerable: true
    });
};
var __copyProps = (to, from, except, desc)=>{
    if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
            get: ()=>from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
        });
    }
    return to;
};
var __toCommonJS = (mod)=>__copyProps(__defProp({}, "__esModule", {
        value: true
    }), mod);
var steps_exports = {};
__export(steps_exports, {
    run: ()=>run,
    runAction: ()=>runAction,
    runMap: ()=>runMap
});
module.exports = __toCommonJS(steps_exports);
var import_utils = __turbopack_context__.r("[project]/node_modules/@genkit-ai/flow/lib/utils.js [app-rsc] (ecmascript)");
function runAction(action, input) {
    return run(action.__action.name, input, ()=>action(input));
}
function run(name, funcOrInput, fn) {
    const func = arguments.length === 3 ? fn : funcOrInput;
    const input = arguments.length === 3 ? funcOrInput : void 0;
    if (!func) {
        throw new Error("unable to resolve run function");
    }
    const ctx = (0, import_utils.getActiveContext)();
    if (!ctx) throw new Error("can only be run from a flow");
    return ctx.run({
        name
    }, input, func);
}
function runMap(stepName, input, fn) {
    return Promise.all(input.map((f)=>run(stepName, ()=>fn(f))));
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
    run,
    runAction,
    runMap
}); //# sourceMappingURL=steps.js.map
}}),
"[project]/node_modules/@genkit-ai/flow/lib/index.mjs [app-rsc] (ecmascript) <locals>": ((__turbopack_context__) => {
"use strict";

var { g: global, __dirname } = __turbopack_context__;
{
__turbopack_context__.s({});
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$flow$2f$lib$2f$chunk$2d$7OAPEGJQ$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/flow/lib/chunk-7OAPEGJQ.mjs [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$flow$2f$node_modules$2f40$genkit$2d$ai$2f$core$2f$lib$2f$index$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$module__evaluation$3e$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/flow/node_modules/@genkit-ai/core/lib/index.mjs [app-rsc] (ecmascript) <module evaluation>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$flow$2f$lib$2f$firestoreStateStore$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/flow/lib/firestoreStateStore.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$flow$2f$lib$2f$flow$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/flow/lib/flow.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$flow$2f$lib$2f$steps$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/flow/lib/steps.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$flow$2f$lib$2f$types$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/flow/lib/types.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$flow$2f$lib$2f$utils$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/flow/lib/utils.js [app-rsc] (ecmascript)");
;
;
;
;
;
;
;
;
 //# sourceMappingURL=index.mjs.map
}}),
"[project]/node_modules/@genkit-ai/flow/lib/index.mjs [app-rsc] (ecmascript) <module evaluation>": ((__turbopack_context__) => {
"use strict";

var { g: global, __dirname } = __turbopack_context__;
{
__turbopack_context__.s({});
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$flow$2f$lib$2f$chunk$2d$7OAPEGJQ$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/flow/lib/chunk-7OAPEGJQ.mjs [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$flow$2f$node_modules$2f40$genkit$2d$ai$2f$core$2f$lib$2f$index$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$module__evaluation$3e$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/flow/node_modules/@genkit-ai/core/lib/index.mjs [app-rsc] (ecmascript) <module evaluation>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$flow$2f$lib$2f$firestoreStateStore$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/flow/lib/firestoreStateStore.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$flow$2f$lib$2f$flow$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/flow/lib/flow.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$flow$2f$lib$2f$steps$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/flow/lib/steps.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$flow$2f$lib$2f$types$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/flow/lib/types.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$flow$2f$lib$2f$utils$2e$js__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/flow/lib/utils.js [app-rsc] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$genkit$2d$ai$2f$flow$2f$lib$2f$index$2e$mjs__$5b$app$2d$rsc$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/@genkit-ai/flow/lib/index.mjs [app-rsc] (ecmascript) <locals>");
}}),

};

//# sourceMappingURL=node_modules_%40genkit-ai_b9624a71._.js.map